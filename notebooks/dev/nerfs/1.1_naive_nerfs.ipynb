{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4123c4da-15c8-47f8-9781-7c14c94e2910",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "---\n",
    "title: Naive NerFs\n",
    "date: 2023-04-01\n",
    "authors:\n",
    "  - name: J. Emmanuel Johnson\n",
    "    affiliations:\n",
    "      - MEOM Lab\n",
    "    roles:\n",
    "      - Primary Programmer\n",
    "    email: jemanjohnson34@gmail.com\n",
    "license: CC-BY-4.0\n",
    "keywords: NerFs, Images\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c19746-c753-434a-9983-6213d436b384",
   "metadata": {},
   "source": [
    "> Neural Fields (NerFs) are an emerging class of coordinate-based neural networks. There has been many developments in the last few years for applying NerFs to data like images. In this tutorial, I will introduce NerFs from the geoscience perspective and highlight some potential advantages to using these methods. I will demonstrate some concrete work on sea surface height interpolation and highlight some of the problems (and potential solutions) I faced when applying this class of methods to spatiotemporal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6028f5f4-c74e-42aa-a147-be448542e2de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import autoroot\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import jax.random as jrandom\n",
    "import optax\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import pandas as pd\n",
    "import equinox as eqx\n",
    "import kernex as kex\n",
    "import finitediffx as fdx\n",
    "import diffrax as dfx\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from jaxtyping import Float, Array, PyTree, ArrayLike\n",
    "import wandb\n",
    "from dataclasses import dataclass\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282f9b4-95c6-457d-8615-122903d71716",
   "metadata": {},
   "source": [
    "## Coordinate-Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c2f41-3ccd-464f-9445-ed894b40c381",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}\\in\\mathbb{R}^D\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b3ff66-05c5-4b1d-a696-9d40a10507db",
   "metadata": {},
   "source": [
    "**Example I**: Time Series\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Input}: && t &\\in \\mathbb{R}^+ \\\\\n",
    "\\text{Outpit}: && f  &: \\mathbb{R}\\rightarrow\\mathbb{R}^U\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc2140e-b5fa-4e9d-a4a0-6e87a5467778",
   "metadata": {},
   "source": [
    "**Example II:** Images\n",
    "\n",
    "$$\n",
    "x,y \\in \\mathbb{R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71086b9-24cb-4b1d-9eab-93ce21ac8d12",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Recap Formulation\n",
    "\n",
    "We are interested in learning non-linear functions $\\boldsymbol{f}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{f}(\\mathbf{x}) &=\n",
    "\\mathbf{w}^\\top\\boldsymbol{\\phi}(\\mathbf{x})+\\mathbf{b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the $\\boldsymbol{\\phi}(\\cdot)$ is a basis function. Neural Fields typically try to learn this basis funciton via a series of composite functions of the form\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}(\\mathbf{x}) =\n",
    "\\boldsymbol{\\phi}_L\\circ\\boldsymbol{\\phi}_{L-1}\n",
    "\\circ\\cdots\\circ\n",
    "\\boldsymbol{\\phi}_2\\circ\\boldsymbol{\\phi}_{1}(\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9495206-f1e1-42d6-beba-13fe42d9253f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Problems\n",
    "\n",
    "Here, we will demonstrate a problem that a naive network has."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac67435-b31d-4788-b79d-3d2e3b5ac1df",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d5566-74c1-484e-9469-e5b95ddd9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FoxDM:\n",
    "    _target_: str = \"jejeqx._src.datamodules.image.ImageFox\"\n",
    "    batch_size: int = 10_000\n",
    "    resize: int = 2\n",
    "    shuffle: bool = False\n",
    "    split_method: str = \"even\"\n",
    "    image_url: str = \"/gpfswork/rech/cli/uvo53rl/projects/jejeqx/data/images/fox.jpg\"\n",
    "\n",
    "\n",
    "config_dm = OmegaConf.structured(FoxDM())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d46d3-df1d-433f-9467-86b6498b0ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = hydra.utils.instantiate(config_dm)\n",
    "dm.setup()\n",
    "\n",
    "\n",
    "init = dm.ds_train[:32]\n",
    "x_init, y_init = init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42021a01-2792-45e9-9e94-fc80241499c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img = dm.load_image()\n",
    "img.shape\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda94acf-8901-4cfc-901b-0b8bb93d430f",
   "metadata": {},
   "source": [
    "## Coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d904070-b0f9-41f6-86b2-8cdf472ae827",
   "metadata": {},
   "source": [
    "$$\n",
    "\\vec{\\mathbf{x}} = \n",
    "\\begin{bmatrix}\n",
    "x \\\\ y\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{y} =\n",
    "\\begin{bmatrix}\n",
    "R \\\\ B \\\\ G\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecc98d-f6ec-4d0a-8ca3-7fdda3429fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Image Shape: {img.shape}\")\n",
    "print(f\"Number of Coords: {len(dm.ds_train):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c674973-f5a6-4d61-9d77-53b1b935bf10",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbada9e-5be2-4abd-b5bc-1693d0ef2523",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "The input data is a coordinate vector, $\\mathbf{x}_\\phi$, of the image coordinates.\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_\\phi \\in \\mathbb{R}^{D_\\phi}\n",
    "$$\n",
    "\n",
    "where $D_\\phi = [\\text{x}, \\text{y}]$. So we are interested in learning a function, $\\boldsymbol{f}$, such that we can input a coordinate vector and output a scaler/vector value of the pixel value.\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\boldsymbol{f}(\\mathbf{x}_\\phi; \\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bed9f-1fdc-4f68-8884-6fb0ab2dacb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "### MLP Layer\n",
    "\n",
    "$$\n",
    "\\mathbf{f}_\\ell(\\mathbf{x}) = \\sigma\\left(\\mathbf{w}^{(\\ell)}\\mathbf{x} + \\mathbf{b}^{(\\ell)} \\right)\n",
    "$$\n",
    "\n",
    "where $\\sigma$ is the *ReLU* activation function.\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{x}) = \\text{ReLU}(\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd64c5a-636b-4bc3-b1bf-df7883087674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from dataclasses import field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Activation:\n",
    "    # _target_: str = \"jejeqx._src.nets.activations.Tanh\"\n",
    "    _target_: str = \"jejeqx._src.nets.activations.ReLU\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IdentityAct:\n",
    "    _target_: str = \"equinox.nn.Identity\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Key:\n",
    "    _target_: str = \"jax.random.PRNGKey\"\n",
    "    seed: int = 123\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MLPModel:\n",
    "    _target_: str = \"equinox.nn.MLP\"\n",
    "    in_size: int = 2\n",
    "    out_size: int = 3\n",
    "    width_size: int = 128\n",
    "    depth: int = 5\n",
    "    activation: Activation = Activation()\n",
    "    final_activation: IdentityAct = IdentityAct()\n",
    "    key: Key = Key(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111365e-50a3-4bfa-a936-925c8912a8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_config = OmegaConf.structured(MLPModel())\n",
    "\n",
    "model = hydra.utils.instantiate(model_config)\n",
    "\n",
    "eqx.tree_pprint(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45db8de-49e2-47d8-b592-113369b122e7",
   "metadata": {},
   "source": [
    "**Note**: We have created a function that takes a vector and outputs a vector. In JAX, we don't have to think about batches until later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6c416-9984-4c56-82ba-d314fa889b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output of models\n",
    "x_vector, y_vector = x_init[0], y_init[0]\n",
    "\n",
    "# predict\n",
    "out_vector = model(x_vector)\n",
    "\n",
    "assert out_vector.shape == y_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1693db6a-7929-4d32-bfa5-529ff16160ad",
   "metadata": {},
   "source": [
    "Now, we can batches by *autovectorizing* using `vmap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52eb84-0891-45a1-b3b2-81f74dd7679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check output of models\n",
    "out = jax.vmap(model)(x_init)\n",
    "\n",
    "assert out.shape == y_init.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3580d3-6711-4cfd-8e73-fc5703c0842b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Optimizer (+ Learning Rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee6f311-5612-46dd-ade3-335142f3c0b3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "For this, we will use a simple adam optimizer with a `learning_rate` of 1e-4. From many studies, it appears that a lower learning rate works well with this methods because there is a lot of data. In addition, a bigger `batch_size` is also desireable. We will set the `num_epochs` to `2_000` which should be good enough for a single image. Obviously more epochs and a better learning rate scheduler would result in better results but this will be sufficient for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16dc47a-bc3e-4bee-8372-4d4503dd049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "num_epochs = 2_000\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Optimizer:\n",
    "    _target_: str = \"optax.adam\"\n",
    "    learning_rate: float = 1e-4\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Scheduler:\n",
    "    _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "    init_value: float = 0.0\n",
    "    peak_value: float = 1e0\n",
    "    warmup_steps: int = 500\n",
    "    end_value: float = 1e-5\n",
    "\n",
    "\n",
    "use_scheduler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca01586-a530-47d7-a552-6cc4042fa9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config = OmegaConf.structured(Optimizer())\n",
    "scheduler_config = OmegaConf.structured(Scheduler())\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = hydra.utils.instantiate(optim_config)\n",
    "\n",
    "if use_scheduler:\n",
    "    num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "    scheduler = hydra.utils.instantiate(\n",
    "        scheduler_config, decay_steps=int(num_epochs * num_steps_per_epoch)\n",
    "    )\n",
    "\n",
    "    # initialize optimizer with scheduler\n",
    "    optimizer = optax.chain(optimizer, optax.scale_by_schedule(scheduler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebbcdb-880b-4749-9302-1aea52dcfbf6",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Scheduler\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<figcaption align = \"center\">\n",
    "  <b>Fig.1 - An example for learning rate reduction when the validation loss stagnates. Source: \n",
    "    <a href=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\">Blog</a>\n",
    "  </b>\n",
    "  </figcaption>\n",
    "</p>\n",
    "\n",
    "We will use a simple learning rate scheduler - `reduce_lr_on_plateau`. This will automatically reduce the learning rate as the validation loss stagnates. It will ensure that we really squeeze out as much performance as possible from our models during the training procedure.We start with a (relatively) high `learning_rate` of `1e-4` so we will set the `patience` to 5 epochs. So if there is no change in with every epoch, we decrease the learning rate by a factor of `0.1`.\n",
    "\n",
    "This is a rather crude (but effective) method but it tends to work well in some situations. A better method might be the `cosine_annealing` method or the `exponential_decay` method. See other [examples](https://www.kaggle.com/code/snnclsr/learning-rate-schedulers/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527fc63-669b-41d1-acbc-fb1af31ecfd4",
   "metadata": {},
   "source": [
    "\n",
    "We are interested posterior of the parameters given the data. So we can use Bayes theorem to express this.\n",
    "\n",
    "$$\n",
    "p(\\boldsymbol{\\theta}|\\mathcal{D}) \\propto p(\\mathcal{D}|\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbd0eaa-d9a0-4537-89b0-7eaec3eb1c69",
   "metadata": {},
   "source": [
    "This can be solved by using the maximimum likelihood method. So in this case, we need to define the likelihood term for the *data*. We can assume a Gaussian likelihood because we are working with continuous data. To make things simple, we can also assume a constant noise.\n",
    "\n",
    "$$\n",
    "p(y|\\mathbf{x};\\boldsymbol{\\theta})=\\mathcal{N}\n",
    "\\left(\n",
    "\\boldsymbol{f}(\\mathbf{x};\\boldsymbol{\\theta}), \\sigma^2\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "This is the *maximum likelihood estimation* problem. If we assume our samples are i.i.d., we get the following minimization problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14ac91-7061-4d00-a80f-81729fb9276c",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\theta} = \\underset{\\boldsymbol{\\theta}}{\\text{argmin}}\n",
    "\\hspace{1mm} \\sum_{y,\\mathbf{x}\\in\\mathcal{D}}-\\log p(y|\\mathbf{x};\\boldsymbol{\\theta})\n",
    "$$\n",
    "\n",
    "Notice the slight of hand: the minimization of the negative log-likelihood is the same as the maxmimization of the log likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baef7ac6-6bc3-4228-83a6-f0cd7c489bdd",
   "metadata": {},
   "source": [
    " If we assume a noise level of 1, i.e. $\\sigma=1$, then this loss reduces to the *mean squared error* (MSE) loss function:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\theta}) = \n",
    "\\frac{1}{|\\mathcal{D}|} \\sum_{n\\in\\mathcal{D}}\n",
    "\\left(y - \\boldsymbol{f_\\theta}(\\mathbf{x})\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7723dab3-04ed-4060-b2de-61fcacd43cb2",
   "metadata": {},
   "source": [
    "We can take minibatches\n",
    "\n",
    "$$\n",
    "\\mathcal{B}=\\left\\{\\mathbf{x}_b,y_b \\right\\}^B_{b=1}\n",
    "$$\n",
    "\n",
    "which is a proper subset of the dataset, $\\mathcal{B} \\mathcal{D}=\\mathcal{B}$.\n",
    "\n",
    "So our new loss function will be:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\theta}) = \n",
    "\\frac{1}{|\\mathcal{B}|} \\sum_{n\\in\\mathcal{B}}\n",
    "\\left(y - \\boldsymbol{f_\\theta}(\\mathbf{x})\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327bdf1-7e7d-458c-99f7-2d85ba48d185",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Trainer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54b919-1dd4-4bad-bd4d-1c9d4dc92a0f",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from jejeqx._src.trainers.base import TrainerModule\n",
    "from jejeqx._src.trainers.callbacks import wandb_model_artifact\n",
    "from jejeqx._src.losses import psnr\n",
    "\n",
    "\n",
    "class RegressorTrainer(TrainerModule):\n",
    "    def __init__(self, model, optimizer, **kwargs):\n",
    "        super().__init__(model=model, optimizer=optimizer, pl_logger=None, **kwargs)\n",
    "\n",
    "    def create_functions(self):\n",
    "        @eqx.filter_value_and_grad\n",
    "        def mse_loss(model, batch):\n",
    "            x, y = batch\n",
    "            pred = jax.vmap(model)(x)\n",
    "            loss = jnp.mean((y - pred) ** 2)\n",
    "            return loss\n",
    "\n",
    "        def train_step(state, batch):\n",
    "            loss, grads = mse_loss(state.params, batch)\n",
    "            state = state.update_state(state, grads)\n",
    "            psnr_loss = psnr(loss)\n",
    "            metrics = {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "            return state, loss, metrics\n",
    "\n",
    "        def eval_step(model, batch):\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        def test_step(model, batch):\n",
    "            x, y = batch\n",
    "            out = jax.vmap(model)(x)\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return out, {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        def predict_step(model, batch):\n",
    "            x, y = batch\n",
    "            out = jax.vmap(model)(x)\n",
    "            return out\n",
    "\n",
    "        return train_step, eval_step, test_step, predict_step\n",
    "\n",
    "    def on_training_end(\n",
    "        self,\n",
    "    ):\n",
    "        if self.pl_logger:\n",
    "            save_dir = Path(self.log_dir).joinpath(self.save_name)\n",
    "            self.save_model(save_dir)\n",
    "            wandb_model_artifact(self)\n",
    "            self.pl_logger.finalize(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1df158c-9126-4e8e-b5ab-ae01c0a34c06",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    seed=seed,\n",
    "    debug=debug,\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864d413-cd6e-4d4f-836a-0f4f182771cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2e3054-e77b-43f7-9b38-73c5566642f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model(\"./checkpoints/checkpoint_model_mlp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f753396-2af9-4f42-8a98-e3d0fdf0eeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5d0fd-628d-45f4-8eff-21be28d1c977",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe234bf6-871e-4180-818d-f4271fffc9ba",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# trainer.save_model(\"./checkpoints/checkpoint_model_mlp.ckpt\")\n",
    "# trainer.save_state(\"checkpoint_state.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a93cc-dff4-4c91-a121-e17a57ce69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52930b97-ecb1-4950-a3fb-b2ff82dd5e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame(\n",
    "    data=[[\"mlp\", metrics[\"loss\"], metrics[\"psnr\"]]],\n",
    "    columns=[\"model\", \"MSE\", \"SNR\"],\n",
    ")\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1336da9-e5aa-4611-bffe-311e810c4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mlp = dm.coordinates_2_image(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc3ea2-0bf7-4aaa-b481-85c053d0b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set(title=\"Original\")\n",
    "ax[1].imshow(out_mlp)\n",
    "ax[1].set(title=\"Naive MLP\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839c3d27-bf8e-4afa-8b97-2be327942819",
   "metadata": {},
   "source": [
    "### Random Fourier Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17fa729-441c-47cc-a50c-0653e43baf0f",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boldsymbol{\\phi}(\\mathbf{x}) = \n",
    "\\sqrt{\\frac{\\sigma^2}{N_{RF}}}\n",
    "\\left[\n",
    "\\cos(\\boldsymbol{\\Omega}\\mathbf{x}),\n",
    "\\sin(\\boldsymbol{\\Omega}\\mathbf{x})\n",
    "\\right]\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\Omega}$ is a random matrix sampled from a Gaussian distribution.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(\\Omega)&\\sim\\mathcal{N}(0,\\boldsymbol{\\Lambda}^{-1}_D) \\\\\n",
    "\\boldsymbol{\\Lambda}_D &= \\text{diag}\n",
    "\\left(\\lambda_1, \\lambda_2, \\ldots, \\lambda_D\\right)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd0e85-5966-4791-a41a-6bb1ed151b66",
   "metadata": {},
   "source": [
    "So our final neural network with the additional basis function:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{f}(\\mathbf{x};\\boldsymbol{\\theta}) =\n",
    "\\mathbf{w}^\\top\\boldsymbol{\\phi}(\\mathbf{x})+\\mathbf{b}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\phi}(\\cdot)$ is the learned *basis network*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe72d26-f3a6-49e2-bf54-f73057fe0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from dataclasses import field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RFFModel:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.ffn.RFFNet\"\n",
    "    in_size: int = 2\n",
    "    out_size: int = 3\n",
    "    width_size: int = 256\n",
    "    depth: int = 5\n",
    "    ard: bool = True\n",
    "    method: str = \"rbf\"\n",
    "    key: Key = Key(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b11c16c-af51-4088-9068-6fb99fadfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_config = OmegaConf.structured(RFFModel())\n",
    "\n",
    "model = hydra.utils.instantiate(model_config)\n",
    "\n",
    "# check output of models\n",
    "out = jax.vmap(model)(x_init)\n",
    "\n",
    "assert out.shape == y_init.shape\n",
    "# eqx.tree_pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afe890-a81a-4988-a8f0-74680db3e1c2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "num_epochs = 6_000\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    seed=seed,\n",
    "    debug=debug,\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "train_more = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a62d131-30ba-4a7c-b1a5-cd963e832319",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8680fba-d97b-4737-9a62-0836ca9a7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer.load_model(\"./checkpoints/checkpoint_model_rff.ckpt\")\n",
    "except:\n",
    "    RuntimeError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424acdfe-55e9-45ea-a2df-ac540a04374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed5085-fec1-4633-ae5a-8d3e50ec19e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if train_more:\n",
    "    metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f95ee48-c169-4182-b4f0-c9d5cc45ebd3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if train_more:\n",
    "    trainer.save_model(\"./checkpoints/checkpoint_model_rff.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a05d7c-70a5-4d13-957f-05ad895e98b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20119d69-c024-435f-9c92-720bc2cc8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.concat(\n",
    "    [\n",
    "        all_metrics,\n",
    "        pd.DataFrame(\n",
    "            data=[[\"rff\", metrics[\"loss\"], metrics[\"psnr\"]]],\n",
    "            columns=[\"model\", \"MSE\", \"SNR\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb16e1-e4ac-457e-8476-f4de37c8af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df068135-8f1a-4aea-baa2-0151a4d6a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_rff = dm.coordinates_2_image(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bc283-1046-46e5-b96b-3d8f3646b21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(12, 4))\n",
    "ax[0].imshow(img)\n",
    "ax[0].set(title=\"Original\")\n",
    "ax[1].imshow(out_mlp)\n",
    "ax[1].set(title=\"Naive MLP\")\n",
    "ax[2].imshow(out_rff)\n",
    "ax[2].set(title=\"Random Fourier Features\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc7541-ac73-4542-a7b6-a3c213d0b7f1",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Custom Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad37874b-a2c3-41c3-8677-97f1351e2cb2",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "\n",
    "**SIREN**\n",
    "\n",
    "One of the most famous methods is the SIREN method. This replaces the standard activation function, $\\sigma$, with a sinusoidal function.\n",
    "\n",
    "$$\n",
    "\\phi(\\mathbf{x})_\\ell = \\sin \n",
    "\\left( \\omega_\\ell\\left( \n",
    "\\mathbf{w}_\\ell\\mathbf{x} + \\mathbf{b}_\\ell\n",
    "\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e08c2-400b-4df3-8e90-aef57359b265",
   "metadata": {},
   "source": [
    "So our final neural network with the additional basis function:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{f}(\\mathbf{x};\\boldsymbol{\\theta}) =\n",
    "\\mathbf{w}^\\top\\boldsymbol{\\phi}(\\mathbf{x})+\\mathbf{b}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\phi}(\\cdot)$ is the learned *basis network*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5b26a-53c2-4a75-9459-738acf31946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Key:\n",
    "    _target_: str = \"jax.random.PRNGKey\"\n",
    "    seed: int = 123\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SirenBasis:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.siren.SirenNet\"\n",
    "    in_size: int = 2\n",
    "    out_size: int = 256\n",
    "    width_size: int = 256\n",
    "    depth: int = 5\n",
    "    key: Key = Key()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LinearModel:\n",
    "    _target_: str = \"equinox.nn.Linear\"\n",
    "    in_features: int = 256\n",
    "    out_features: int = 3\n",
    "    use_bias: bool = True\n",
    "    key: Key = Key()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class NerFModel:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.base.NerF\"\n",
    "    network: LinearModel = LinearModel()\n",
    "    basis_net: SirenBasis = SirenBasis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e633a17-d8a3-4d4f-a221-13b9a6f4c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jejeqx._src.nets.nerfs.base import NerF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941cc3b-fe32-4d17-9262-7187570a98b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_config = OmegaConf.structured(NerFModel())\n",
    "\n",
    "model = hydra.utils.instantiate(model_config)\n",
    "\n",
    "# check output of models\n",
    "out = jax.vmap(model)(x_init)\n",
    "\n",
    "# assert out.shape == y_init.shape\n",
    "# eqx.tree_pprint(model)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21745e2c-1e75-40e7-9720-766872d90763",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    seed=seed,\n",
    "    debug=debug,\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "train_more = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a800d9-4f3b-4ca9-b04d-3537a7a506ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7118ff-61ce-4343-9dd1-c996cf2422fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer.load_model(\"./checkpoints/checkpoint_model_siren.ckpt\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1882947c-409a-414c-97a4-cd1d568ff82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdccbfc9-f0ec-462d-b03e-62255d8064b6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if train_more:\n",
    "    metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dd4aa9-16f7-42a3-9c02-87783302ddfe",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if train_more:\n",
    "    trainer.save_model(\"./checkpoints/checkpoint_model_siren.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08712e1b-e9f5-42b9-9fdd-b08daf269ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1329a4-733f-479e-a301-ae19c51f9394",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.concat(\n",
    "    [\n",
    "        all_metrics,\n",
    "        pd.DataFrame(\n",
    "            data=[[\"siren\", metrics[\"loss\"], metrics[\"psnr\"]]],\n",
    "            columns=[\"model\", \"MSE\", \"SNR\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e0507-8f48-46b3-a64e-3b5a4ef22ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_siren = dm.coordinates_2_image(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38becb2-7725-48f3-a560-652a73ca4662",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=2, figsize=(8, 8))\n",
    "\n",
    "ax[0, 0].imshow(img)\n",
    "ax[0, 0].set(title=\"Original\")\n",
    "ax[0, 1].imshow(out_mlp)\n",
    "ax[0, 1].set(title=\"MLP\")\n",
    "ax[1, 0].imshow(out_rff)\n",
    "ax[1, 0].set(title=\"Fourier Features\")\n",
    "ax[1, 1].imshow(out_siren)\n",
    "ax[1, 1].set(title=\"Siren\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d87397-fea3-42ea-83f9-3c5a693f2aab",
   "metadata": {},
   "source": [
    "## Multiplicative Filter Networks (MFN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8b6e0d-df13-44c7-b631-61e52c825404",
   "metadata": {},
   "source": [
    "### Fourier Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8240d-04bb-4325-a0a6-83e56ecb489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "num_epochs = 2_000\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Optimizer:\n",
    "    _target_: str = \"optax.adam\"\n",
    "    learning_rate: float = 1e-4\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Scheduler:\n",
    "    _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "    init_value: float = 0.0\n",
    "    peak_value: float = 1e0\n",
    "    warmup_steps: int = 500\n",
    "    end_value: float = 1e-5\n",
    "\n",
    "\n",
    "use_scheduler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e974db7-5a4e-4876-a231-ae83f64c8bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config = OmegaConf.structured(Optimizer())\n",
    "scheduler_config = OmegaConf.structured(Scheduler())\n",
    "\n",
    "# initialize optimizer\n",
    "optimizer = hydra.utils.instantiate(optim_config)\n",
    "\n",
    "if use_scheduler:\n",
    "    num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "    scheduler = hydra.utils.instantiate(\n",
    "        scheduler_config, decay_steps=int(num_epochs * num_steps_per_epoch)\n",
    "    )\n",
    "\n",
    "    # initialize optimizer with scheduler\n",
    "    optimizer = optax.chain(optimizer, optax.scale_by_schedule(scheduler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803899e2-5808-4e24-8bdd-f9512860be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from dataclasses import field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IdentityAct:\n",
    "    _target_: str = \"equinox.nn.Identity\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Key:\n",
    "    _target_: str = \"jax.random.PRNGKey\"\n",
    "    seed: int = 123\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MFNModel:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.mfn.FourierNet\"\n",
    "    in_size: int = 2\n",
    "    out_size: int = 3\n",
    "    width_size: int = 256\n",
    "    depth: int = 4\n",
    "    final_activation: IdentityAct = IdentityAct()\n",
    "    key: Key = Key(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461ce37e-299d-4c3b-b411-6635b02ecfc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01486e-aec2-452e-9290-16fd6fa1d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_config = OmegaConf.structured(MFNModel())\n",
    "\n",
    "model = hydra.utils.instantiate(model_config)\n",
    "\n",
    "# eqx.tree_pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5968d-db9c-4264-9b90-d4c5ab8a8ba6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    seed=seed,\n",
    "    debug=debug,\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "train_more = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3f91ed-8f38-4df2-906a-40d7b56862fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e71e7-1dc3-400f-8620-55f0a3d69c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer.load_model(\"./checkpoints/checkpoint_model_mfnfourier.ckpt\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9731f7a1-a7ce-4cba-9890-d481327762dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901f6b2-0cdb-40a4-955f-c99156c870a7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if train_more:\n",
    "    metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749d85a9-ddef-4b4b-b5eb-09331108abc5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if train_more:\n",
    "    trainer.save_model(\"./checkpoints/checkpoint_model_mfnfourier.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f09764-4129-400e-b512-df784120e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c08a1c-e119-4680-8533-63637dbaa286",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.concat(\n",
    "    [\n",
    "        all_metrics,\n",
    "        pd.DataFrame(\n",
    "            data=[[\"mfnfourier\", metrics[\"loss\"], metrics[\"psnr\"]]],\n",
    "            columns=[\"model\", \"MSE\", \"SNR\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f8397-c65f-4285-834e-88bc5ce54562",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mfn_fourier = dm.coordinates_2_image(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc8f715-9492-4d27-9159-ab2ca005ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=3, figsize=(8, 8))\n",
    "\n",
    "ax[0, 0].imshow(img)\n",
    "ax[0, 0].set(title=\"Original\")\n",
    "ax[0, 1].imshow(out_mlp)\n",
    "ax[0, 1].set(title=\"MLP\")\n",
    "ax[1, 0].imshow(out_rff)\n",
    "ax[1, 0].set(title=\"Fourier Features\")\n",
    "ax[1, 1].imshow(out_siren)\n",
    "ax[1, 1].set(title=\"Siren\")\n",
    "ax[2, 1].imshow(out_mfn_fourier)\n",
    "ax[2, 1].set(title=\"MFN (FourierNet)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4ca6bf-2cfd-4ee7-9fab-b26346b92954",
   "metadata": {},
   "source": [
    "### GaborNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca3a6b-dbf7-47fe-b535-e0a194db1bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from dataclasses import field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IdentityAct:\n",
    "    _target_: str = \"equinox.nn.Identity\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Key:\n",
    "    _target_: str = \"jax.random.PRNGKey\"\n",
    "    seed: int = 123\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MFNModel:\n",
    "    _target_: str = \"jejeqx._src.nets.nerfs.mfn.GaborNet\"\n",
    "    in_size: int = 2\n",
    "    out_size: int = 3\n",
    "    width_size: int = 256\n",
    "    depth: int = 4\n",
    "    final_activation: IdentityAct = IdentityAct()\n",
    "    key: Key = Key(seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7574aa-a2ef-4f67-98ab-986fe61d28e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = jrandom.normal(key=jrandom.PRNGKey(123), shape=(10,))\n",
    "y_ = jrandom.normal(key=jrandom.PRNGKey(42), shape=(10, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29240d-e193-4fa1-9e15-e458a3b738c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, cdist\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e57a09-c82b-4bd3-815a-58728bd083dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdist(einops.repeat(x_, \"D -> D R\", R=20), y_, metric=\"sqeuclidean\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cd343-5425-4afc-8541-d0c8e457e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, y):\n",
    "    a = np.sum(x**2, axis=-1)[..., None]\n",
    "    b = np.sum(y**2, axis=0)[None, :]\n",
    "    c = -2 * a @ b\n",
    "\n",
    "    D = a + b + c\n",
    "    return D.squeeze()\n",
    "\n",
    "\n",
    "def norm2(x, y):\n",
    "    a = np.sum(x**2, axis=-1)[..., None]\n",
    "    b = np.sum(y**2, axis=0)[None, :]\n",
    "    c = np.einsum(\"i,ij->j\", x, y)\n",
    "\n",
    "    D = a + b - 2 * c\n",
    "    return D.squeeze()\n",
    "\n",
    "\n",
    "def norm3(x, y):\n",
    "    a_min_b = x[..., None] - y\n",
    "\n",
    "    D = np.einsum(\"ij,ij->j\", a_min_b, a_min_b)\n",
    "\n",
    "    return np.sqrt(D).squeeze()\n",
    "\n",
    "\n",
    "def norm4(x, y):\n",
    "    return np.linalg.norm(x[..., None] - y, ord=2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88317728-5c7b-4d6c-8916-9d2e6e3f8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm(x_, y_), norm2(x_, y_), norm3(x_, y_), norm4(x_, y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63b85b-88b9-493c-affd-60ed5039f120",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_ = norm(x_, y_)\n",
    "o__ = norm2(x_, y_)\n",
    "o_.shape, o__.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c789dfd-7e34-4262-9248-2968985b6a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049562de-ce7d-4e85-8b5a-54a80eb33a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "o__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5697f7bb-0c72-440e-b452-f8b1d258c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (x_**2).sum(axis=-1)[..., None]\n",
    "b = (y_**2).sum(axis=0)[None, ...]\n",
    "c = jnp.einsum(\"i,ij -> j\", x_, y_)\n",
    "a.shape, b.shape, (a + b).shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de623904-d33d-4f44-8ee3-11c0622a96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_.shape, y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14701d5-4db2-4650-bac3-c6f01946bb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jejeqx._src.nets.nerfs.mfn import GaborLayer\n",
    "\n",
    "layer = GaborLayer(2, 3)\n",
    "layer(x_init[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5103d64-6247-4104-9efa-4b125a21dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model\n",
    "model_config = OmegaConf.structured(MFNModel())\n",
    "\n",
    "model = hydra.utils.instantiate(model_config)\n",
    "\n",
    "# eqx.tree_pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631b046f-6403-43c4-befd-4339d01a603a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55d889-9555-4bad-9682-0e6937c84d6e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model,\n",
    "    optimizer,\n",
    "    seed=seed,\n",
    "    debug=debug,\n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir,\n",
    ")\n",
    "\n",
    "train_more = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ebc351-ab48-4a72-a6f4-3aeaa8bcde3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8b3348-fbe4-4f82-87ca-2b4b0d730700",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trainer.load_model(\"./checkpoints/checkpoint_model_mfngabor.ckpt\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a30922-40d7-4c0f-9f1a-e183ccb980a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b92a8-1072-4c40-b7a7-ac46a04ed65a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#\n",
    "if train_more:\n",
    "    metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4abdb7-daf8-4d81-bd9e-b54d899da687",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "if train_more:\n",
    "    trainer.save_model(\"./checkpoints/checkpoint_model_mfngabor.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0b905-32b0-4117-b77d-3382bdc30300",
   "metadata": {},
   "outputs": [],
   "source": [
    "out, metrics = trainer.test_model(dm.test_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ab0025-e04b-48b0-b59b-f12ea16cf0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.concat(\n",
    "    [\n",
    "        all_metrics,\n",
    "        pd.DataFrame(\n",
    "            data=[[\"mfngabor\", metrics[\"loss\"], metrics[\"psnr\"]]],\n",
    "            columns=[\"model\", \"MSE\", \"SNR\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5532bc87-08ee-4b0c-9020-952a6f6b6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_mfn_gabor = dm.coordinates_2_image(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba8785-9eb5-4844-affd-fc1b351917cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=3, figsize=(8, 8))\n",
    "\n",
    "ax[0, 0].imshow(img)\n",
    "ax[0, 0].set(title=\"Original\")\n",
    "ax[0, 1].imshow(out_mlp)\n",
    "ax[0, 1].set(title=\"MLP\")\n",
    "ax[1, 0].imshow(out_rff)\n",
    "ax[1, 0].set(title=\"Fourier Features\")\n",
    "ax[1, 1].imshow(out_siren)\n",
    "ax[1, 1].set(title=\"Siren\")\n",
    "ax[2, 0].imshow(out_mfn_fourier)\n",
    "ax[2, 0].set(title=\"MFN (Fourier)\")\n",
    "ax[2, 1].imshow(out_mfn_gabor)\n",
    "ax[2, 1].set(title=\"MFN (Gabor)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d026e10-c9f9-467a-a8e5-8e0551b251e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e081c-028b-4f26-a798-10df473de07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5edeb2-e193-48ae-8a4f-9cb04fde5a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-jejeqx]",
   "language": "python",
   "name": "conda-env-miniconda3-jejeqx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
