{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4123c4da-15c8-47f8-9781-7c14c94e2910",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "---\n",
    "title: Sparse Observations\n",
    "date: 2023-04-01\n",
    "authors:\n",
    "  - name: J. Emmanuel Johnson\n",
    "    affiliations:\n",
    "      - MEOM Lab\n",
    "    roles:\n",
    "      - Primary Programmer\n",
    "    email: jemanjohnson34@gmail.com\n",
    "license: CC-BY-4.0\n",
    "keywords: NerFs, SWOT\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6028f5f4-c74e-42aa-a147-be448542e2de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    }
   ],
   "source": [
    "import autoroot\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import jax.random as jrandom\n",
    "import numpy as np\n",
    "import numba as nb\n",
    "import equinox as eqx\n",
    "import kernex as kex\n",
    "import finitediffx as fdx\n",
    "import diffrax as dfx\n",
    "import xarray as xr\n",
    "import metpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from jaxtyping import Float, Array, PyTree, ArrayLike\n",
    "import wandb\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "from sklearn import pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from jejeqx._src.transforms.dataframe.spatial import Spherical2Cartesian\n",
    "from jejeqx._src.transforms.dataframe.temporal import TimeDelta\n",
    "from jejeqx._src.transforms.dataframe.scaling import MinMaxDF\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "# Ensure TF does not see GPU and grab all GPU memory.\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71086b9-24cb-4b1d-9eab-93ce21ac8d12",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Recap Formulation\n",
    "\n",
    "We are interested in learning non-linear functions $\\boldsymbol{f}$.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{f}(\\mathbf{x}) &=\n",
    "\\mathbf{w}^\\top\\boldsymbol{\\phi}(\\mathbf{x})+\\mathbf{b}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where the $\\boldsymbol{\\phi}(\\cdot)$ is a basis function. Neural Fields typically try to learn this basis funciton via a series of composite functions of the form\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}(\\mathbf{x}) =\n",
    "\\boldsymbol{\\phi}_L\\circ\\boldsymbol{\\phi}_{L-1}\n",
    "\\circ\\cdots\\circ\n",
    "\\boldsymbol{\\phi}_2\\circ\\boldsymbol{\\phi}_{1}(\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9495206-f1e1-42d6-beba-13fe42d9253f",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Problems\n",
    "\n",
    "Here, we will demonstrate a problem that a naive network has."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac67435-b31d-4788-b79d-3d2e3b5ac1df",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Sparse Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a64840-9539-4eef-b173-436d7abfe6f8",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "In the previous examples, we were demonstrating how NerFs perform when we have some clean simulation. \n",
    "However, in many real problems, we do not have access to such clean\n",
    "\n",
    "For this example, we are going to look at the case when we have very sparse observations: as in the case with satellite altimetry data like SWOT. In this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aefda25b-01ae-4654-b4ce-03c17732a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -nc \"https://s3.us-east-1.wasabisys.com/melody/osse_data/data/gridded_data_swot_wocorr/dataset_nadir_0d_swot.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80de7073-939d-4ab9-a419-d5564a660681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dde389d0-00ed-4b52-b577-f97c1231a66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"/gpfswork/rech/cli/uvo53rl/projects/jejeqx/data/natl60/dataset_nadir_0d_swot.nc\").is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940d5566-74c1-484e-9469-e5b95ddd9d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "\n",
    "@dataclass\n",
    "class Subset:\n",
    "    _target_: str = \"builtins.slice\"\n",
    "    _args_: List = field(default_factory=lambda :[\"2013-01-01\", \"2013-01-10\"])\n",
    "\n",
    "files = [\n",
    "    \"/gpfswork/rech/yrf/commun/data_challenges/dc20a_osse/work_eman/ml_ready/swot1nadir5.nc\",\n",
    "]\n",
    "\n",
    "@dataclass\n",
    "class SSHDM:\n",
    "    _target_: str = \"jejeqx._src.datamodules.coords.AlongTrackDM\"\n",
    "    paths: List[str] = field(default_factory=lambda : files)\n",
    "    batch_size: int = 10_000\n",
    "    shuffle: bool = True\n",
    "    train_size: float = 0.80\n",
    "    subset_size: float = 0.75\n",
    "    spatial_coords: List = field(default_factory=lambda : [\"lat\", \"lon\"])\n",
    "    temporal_coords: List = field(default_factory=lambda: [\"time\"])\n",
    "    variables: List = field(default_factory=lambda : [\"ssh_obs\"])\n",
    "    \n",
    "# spatial transform\n",
    "spatial_transforms = Pipeline([\n",
    "    (\"cartesian3d\", Spherical2Cartesian(radius=1.0, units=\"degrees\")),\n",
    "    (\"spatialminmax\", MinMaxDF([\"x\", \"y\", \"z\"], -1, 1)),\n",
    "])\n",
    "\n",
    "temporal_transforms = Pipeline([\n",
    "    (\"timedelta\", TimeDelta(\"2012-10-01\", 1, \"s\")),\n",
    "    (\"timeminmax\", MinMaxDF([\"time\"], -1, 1)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5bf5af-e023-4d3b-a5bc-4bd14de193a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfsdswork/projects/rech/cli/uvo53rl/projects/jejeqx/jejeqx/_src/transforms/dataframe/temporal.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"time\"] = time\n",
      "/gpfsdswork/projects/rech/cli/uvo53rl/projects/jejeqx/jejeqx/_src/transforms/dataframe/scaling.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[self.columns] = X_var\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.9347430686690226,\n",
       " 0.99583009948174,\n",
       " (32, 3),\n",
       " -0.8538637215757465,\n",
       " 0.6823056834045169,\n",
       " (32, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = {\"time\": slice(\"2012-10-22\", \"2012-11-22\")}\n",
    "\n",
    "config_dm = OmegaConf.structured(SSHDM())\n",
    "\n",
    "dm = hydra.utils.instantiate(\n",
    "    config_dm,\n",
    "    select=select,\n",
    "    spatial_transform=spatial_transforms,\n",
    "    temporal_transform=temporal_transforms,\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "\n",
    "\n",
    "init = dm.ds_train[:32]\n",
    "x_init, t_init, y_init = init[\"spatial\"], init[\"temporal\"], init[\"data\"]\n",
    "x_init.min(), x_init.max(), x_init.shape, t_init.min(), t_init.max(), t_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aada7fe-c387-4dee-aea9-f60b0c698013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240855"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e367177-80a4-4490-acdc-02d6a2932f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda_obs = dm.load_xrds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d5da277-9e83-4475-863c-d853d64710ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(ncols=1, figsize=(5,4))\n",
    "\n",
    "# xrda_obs.ssh_obs.isel(time=1).plot.pcolormesh(ax=ax, cmap=\"viridis\")\n",
    "# ax.set(title=\"Original\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6041259-00a2-4de1-85b1-2569744ee922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geoviews as gv\n",
    "# import geoviews.feature as gf\n",
    "# from cartopy import crs\n",
    "\n",
    "# gv.extension('bokeh', 'matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2043e33-8790-4e66-af64-c7f0f2758af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xrda_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405d8c5d-7fe3-4d1f-8943-d8268fc87de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = gv.Dataset(xrda_obs)\n",
    "# ensemble1 = dataset.to(gv.Image, ['lon', 'lat'], \"ssh_obs\")\n",
    "# gv.output(ensemble1.opts(cmap='viridis', colorbar=True, fig_size=200, backend='matplotlib') * gf.coastline(),\n",
    "#           backend='matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "689ffb2f-decd-4b19-ad3a-ee264c1088df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 5e-3\n",
    "# num_epochs = 5_000\n",
    "# num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "# @dataclass\n",
    "# class FoxDataModule:\n",
    "#     _target_: str = \"jejeqx._src.datamodules.image.ImageFox\"\n",
    "#     batch_size: int = 10_000\n",
    "#     train_size: float = 0.5\n",
    "#     shuffle: bool = False\n",
    "#     split_method: str = \"even\"\n",
    "#     resize: int = 4\n",
    "    \n",
    "# @dataclass\n",
    "# class Training:\n",
    "#     num_epochs: int = 2_000\n",
    "\n",
    "# @dataclass\n",
    "# class Model:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.siren.SirenNet\"\n",
    "#     in_size: int = 2\n",
    "#     out_size: int = 3\n",
    "#     width_size: int = 128\n",
    "#     depth: int = 5\n",
    "\n",
    "# @dataclass\n",
    "# class Optimizer:\n",
    "#     _target_: str = \"optax.adam\"\n",
    "#     learning_rate: float = lr\n",
    "    \n",
    "# @dataclass\n",
    "# class Scheduler:\n",
    "#     _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "#     init_value: float = 0.0\n",
    "#     peak_value: float = lr\n",
    "#     warmup_steps: int = 100\n",
    "#     decay_steps: int = int(num_epochs * num_steps_per_epoch)\n",
    "#     end_value: float = 0.01 * lr\n",
    "    \n",
    "# @dataclass\n",
    "# class Config:\n",
    "#     datamodule: FoxDataModule = FoxDataModule()\n",
    "#     model: Model = Model()\n",
    "#     optimizer: Optimizer = Optimizer()\n",
    "#     scheduler: Scheduler = Scheduler()\n",
    "#     num_epochs: int = 2_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68dc918a-caec-4696-9e70-1d101b62d0e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import optax\n",
    "\n",
    "# config = Config()\n",
    "# config = OmegaConf.structured(Config())\n",
    "\n",
    "# # initialize datamodule\n",
    "# dm = hydra.utils.instantiate(config.datamodule)\n",
    "\n",
    "# dm.setup()\n",
    "\n",
    "\n",
    "# # initialize optimizer\n",
    "# optimizer = hydra.utils.instantiate(config.optimizer)\n",
    "\n",
    "# # initialize scheduler\n",
    "# num_steps_per_epoch = len(dm.ds_train)\n",
    "# decay_steps = int(num_steps_per_epoch * config.num_epochs)\n",
    "# schedule_fn = hydra.utils.instantiate(config.scheduler, decay_steps=decay_steps)\n",
    "\n",
    "# # initialize optimizer + scheduler\n",
    "# optimizer = optax.chain(optimizer, optax.scale_by_schedule(schedule_fn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b7ad02-d923-4fca-b106-ce87652b9995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibatch = next(iter(dm.train_dataloader()))\n",
    "\n",
    "# print(ibatch[0].shape, ibatch[1].shape, type(ibatch[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c674973-f5a6-4d61-9d77-53b1b935bf10",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbada9e-5be2-4abd-b5bc-1693d0ef2523",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "The input data is a coordinate vector, $\\mathbf{x}_\\phi$, of the image coordinates.\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_\\phi \\in \\mathbb{R}^{D_\\phi}\n",
    "$$\n",
    "\n",
    "where $D_\\phi = [\\text{x}, \\text{y}]$. So we are interested in learning a function, $\\boldsymbol{f}$, such that we can input a coordinate vector and output a scaler/vector value of the pixel value.\n",
    "\n",
    "$$\n",
    "\\mathbf{u} = \\boldsymbol{f}(\\mathbf{x}_\\phi; \\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667bed9f-1fdc-4f68-8884-6fb0ab2dacb8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "user_expressions": []
   },
   "source": [
    "### SIREN Layer\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\phi}^{(\\ell)}(\\mathbf{x}) = \\sin\n",
    "\\left(\n",
    "\\omega^{(\\ell)}\\left(\n",
    "\\mathbf{w}^{(\\ell)}\\mathbf{x} + \\mathbf{b}^{(\\ell)} + \\mathbf{s}^{(\\ell)}\n",
    "\\right)\\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{s}$ is the modulation\n",
    "\n",
    "$$\n",
    "\\mathbf{s}^{(\\ell)} = \\mathbf{w}_z^{(\\ell)}\\mathbf{z} + \\mathbf{b}_z^{(\\ell)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75094d0f-21d6-4422-b4ea-3ab4c66e60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jejeqx._src.nets.nerfs.ffn import RFFLayer\n",
    "\n",
    "model_name = \"rff\"\n",
    "\n",
    "\n",
    "model = eqx.nn.Sequential(\n",
    "    [RFFLayer(in_dim=4, num_features=256, out_dim=256, key=jrandom.PRNGKey(42)),\n",
    "     RFFLayer(in_dim=256, num_features=256, out_dim=256, key=jrandom.PRNGKey(123)),\n",
    "     RFFLayer(in_dim=256, num_features=256, out_dim=256, key=jrandom.PRNGKey(23)),\n",
    "     RFFLayer(in_dim=256, num_features=256, out_dim=1, key=jrandom.PRNGKey(32)),\n",
    "    ]\n",
    ")\n",
    "# check output of models\n",
    "out = jax.vmap(model)(jnp.hstack([x_init,t_init]))\n",
    "\n",
    "assert out.shape == y_init.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20e6f159-2a36-41e4-be76-4609c14f5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jejeqx._src.nets.nerfs.siren import SirenNet\n",
    "\n",
    "# model_name = \"siren\"\n",
    "\n",
    "# model = eqx.nn.Sequential(\n",
    "#     [SirenNet(\n",
    "#         in_size=4, out_size=256, width_size=256, depth=5, key=jrandom.PRNGKey(42)\n",
    "#     ),\n",
    "#      eqx.nn.Linear(in_features=256, out_features=1, key=jrandom.PRNGKey(123))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # check output of models\n",
    "# # out = jax.vmap(model, in_axes=(0,0))(x_init, t_init)\n",
    "# out = jax.vmap(model)(jnp.hstack([x_init, t_init]))\n",
    "\n",
    "# assert out.shape == y_init.shape\n",
    "# # eqx.tree_pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcf37fd0-e78c-42ab-9608-99e34548fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @dataclass\n",
    "# class Key:\n",
    "#     _target_: str = \"jax.random.PRNGKey\"\n",
    "#     seed: int = 123\n",
    "\n",
    "# @dataclass\n",
    "# class SirenBasis:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.siren.SirenNet\"\n",
    "#     in_size: int = 4\n",
    "#     out_size: int = 128\n",
    "#     width_size: int = 128\n",
    "#     depth: int = 5\n",
    "#     key: Key = Key()\n",
    "    \n",
    "# @dataclass\n",
    "# class LinearModel:\n",
    "#     _target_: str = \"equinox.nn.Linear\"\n",
    "#     in_features: int = 128\n",
    "#     out_features: int = 1\n",
    "#     use_bias: bool = True\n",
    "#     key: Key = Key()\n",
    "    \n",
    "# @dataclass\n",
    "# class NerFModel:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.base.NerF\"\n",
    "#     basis_net: SirenBasis = SirenBasis()\n",
    "#     network: LinearModel = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c72590-0ac2-4e54-a16c-4c32bd7fa961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff0afbf6-d606-4097-9798-be048c343974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_dim = 64\n",
    "\n",
    "# @dataclass\n",
    "# class Key:\n",
    "#     _target_: str = \"jax.random.PRNGKey\"\n",
    "#     seed: int = 123\n",
    "    \n",
    "# @dataclass\n",
    "# class Activation:\n",
    "#     # _target_: str = \"jejeqx._src.nets.activations.Tanh\"\n",
    "#     _target_: str = \"jejeqx._src.nets.activations.ReLU\"\n",
    "    \n",
    "# @dataclass\n",
    "# class IdentityAct:\n",
    "#     _target_: str = \"equinox.nn.Identity\"\n",
    "\n",
    "# @dataclass\n",
    "# class ModSirenBasis:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.siren.LatentModulatedSirenNet\"\n",
    "#     in_size: int = 3\n",
    "#     out_size: int = 128\n",
    "#     width_size: int = 128\n",
    "#     depth: int = 4\n",
    "#     latent_dim: int = latent_dim\n",
    "#     latent_width: int = 64\n",
    "#     latent_depth: int = 1\n",
    "#     key: Key = Key()\n",
    "    \n",
    "# # @dataclass\n",
    "# # class ParamNet:\n",
    "# #     _target_: str = \"equinox.nn.MLP\"\n",
    "# #     in_size: int = 1\n",
    "# #     out_size: int = 128\n",
    "# #     width_size: int = 128\n",
    "# #     depth: int = 1\n",
    "# #     activation: Activation = Activation()\n",
    "# #     final_activation: IdentityAct = IdentityAct()\n",
    "# #     key: Key = Key(seed=42)\n",
    "\n",
    "\n",
    "# # @dataclass\n",
    "# # class ParamNet:\n",
    "# #     _target_: str = \"jejeqx._src.nets.time_net.TimeFourier\"\n",
    "# #     in_features: int = 1\n",
    "# #     out_features: int = 128\n",
    "# #     lmbd: float = 0.5\n",
    "# #     bounded: bool = True\n",
    "# #     key: Key = Key()\n",
    "\n",
    "# @dataclass\n",
    "# class TimeEncoder:\n",
    "#     # _target_: str = \"jejeqx._src.nets.nerfs.encoders.SinusoidalEncoding\"\n",
    "#     # _target_: str = \"jejeqx._src.nets.time_net.TimeLog\"\n",
    "#     _target_: str = \"jejeqx._src.nets.time_net.TimeIdentity\"\n",
    "#     out_features: int = 128\n",
    "#     key: Key = Key()\n",
    "    \n",
    "# @dataclass\n",
    "# class TimeNet:\n",
    "#     _target_: str = \"equinox.nn.MLP\"\n",
    "#     in_size: int = TimeEncoder().out_features\n",
    "#     out_size: int = latent_dim\n",
    "#     width_size: int = 64\n",
    "#     depth: int = 0\n",
    "#     activation: Activation = Activation()\n",
    "#     final_activation: IdentityAct = IdentityAct()\n",
    "#     key: Key = Key(seed=42)\n",
    "    \n",
    "# @dataclass\n",
    "# class ParamNet:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.base.NerF\"\n",
    "#     basis_net: TimeEncoder = TimeEncoder()\n",
    "#     network: TimeNet = TimeNet()\n",
    "    \n",
    "# @dataclass\n",
    "# class LinearModel:\n",
    "#     _target_: str = \"equinox.nn.Linear\"\n",
    "#     in_features: int = ModSirenBasis().out_size\n",
    "#     out_features: int = 1\n",
    "#     use_bias: bool = True\n",
    "#     key: Key = Key()\n",
    "\n",
    "    \n",
    "# @dataclass\n",
    "# class NerFModel:\n",
    "#     _target_: str = \"jejeqx._src.nets.nerfs.base.ShapeParamNerF\"\n",
    "#     mod_shape_net: ModSirenBasis = ModSirenBasis()\n",
    "#     param_net: ParamNet = ParamNet()\n",
    "#     network: LinearModel = LinearModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef26f7b7-3df8-4b9d-a130-ed8989ad8a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initialize model\n",
    "# model_config = OmegaConf.structured(NerFModel())\n",
    "\n",
    "# model = hydra.utils.instantiate(model_config)\n",
    "\n",
    "# # check output of models\n",
    "# # out = jax.vmap(model, in_axes=(0,0))(x_init, t_init)\n",
    "# out = jax.vmap(model)(jnp.hstack([x_init, t_init]))\n",
    "\n",
    "# assert out.shape == y_init.shape\n",
    "# # eqx.tree_pprint(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0cf1214f-4d3d-49de-a533-bdb16d5adc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.min(), out.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26253b4b-f571-4839-a445-06c465c7ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_name = \"./checkpoints/checkpoint_model_lmsiren_ssh.ckpt\"\n",
    "# model_mod_shape_net = eqx.tree_deserialise_leaves(f\"{save_name}\", model.mod_shape_net)\n",
    "\n",
    "# # To partially load weights: in this case load everything except the final layer.\n",
    "# model = eqx.tree_at(lambda model: model.mod_shape_net, model, model_mod_shape_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e137a3a4-7934-46b6-9569-b39370464da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_name = \"./checkpoints/checkpoint_model_stlmsiren_ssh_swot.ckpt\"\n",
    "\n",
    "# model_mod_shape_net = eqx.tree_deserialise_leaves(f\"{save_name}\", model.mod_shape_net)\n",
    "\n",
    "# # To partially load weights: in this case load everything except the final layer.\n",
    "# model = eqx.tree_at(lambda model: model.mod_shape_net, model, model_mod_shape_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87d7f490-b991-478a-8e88-d15458eb3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3580d3-6711-4cfd-8e73-fc5703c0842b",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Optimizer (+ Learning Rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee6f311-5612-46dd-ade3-335142f3c0b3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "For this, we will use a simple adam optimizer with a `learning_rate` of 1e-4. From many studies, it appears that a lower learning rate works well with this methods because there is a lot of data. In addition, a bigger `batch_size` is also desireable. We will set the `num_epochs` to `1_000` which should be good enough for a single image. Obviously more epochs and a better learning rate scheduler would result in better results but this will be sufficient for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a16dc47a-bc3e-4bee-8372-4d4503dd049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Optimizer:\n",
    "    _target_: str = \"optax.adam\"\n",
    "    learning_rate: float = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ca01586-a530-47d7-a552-6cc4042fa9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_config = OmegaConf.structured(Optimizer())\n",
    "\n",
    "optim = hydra.utils.instantiate(optim_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ebbcdb-880b-4749-9302-1aea52dcfbf6",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Scheduler\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\" alt=\"drawing\" width=\"300\"/>\n",
    "<figcaption align = \"center\">\n",
    "  <b>Fig.1 - An example for learning rate reduction when the validation loss stagnates. Source: \n",
    "    <a href=\"http://www.bdhammel.com/assets/learning-rate/resnet_loss.png\">Blog</a>\n",
    "  </b>\n",
    "  </figcaption>\n",
    "</p>\n",
    "\n",
    "We will use a simple learning rate scheduler - `reduce_lr_on_plateau`. This will automatically reduce the learning rate as the validation loss stagnates. It will ensure that we really squeeze out as much performance as possible from our models during the training procedure.We start with a (relatively) high `learning_rate` of `1e-4` so we will set the `patience` to 5 epochs. So if there is no change in with every epoch, we decrease the learning rate by a factor of `0.1`.\n",
    "\n",
    "This is a rather crude (but effective) method but it tends to work well in some situations. A better method might be the `cosine_annealing` method or the `exponential_decay` method. See other [examples](https://www.kaggle.com/code/snnclsr/learning-rate-schedulers/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99036348-eb3d-4d53-835d-4262c7546c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "# # FROM SCRATCH\n",
    "# @dataclass\n",
    "# class Scheduler:\n",
    "#     _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "#     init_value: float = 0.0\n",
    "#     peak_value: float = 1e0\n",
    "#     warmup_steps: int = 500\n",
    "#     end_value: float = 1e-4\n",
    "\n",
    "# FINE TUNE\n",
    "@dataclass\n",
    "class Scheduler:\n",
    "    _target_: str = \"optax.warmup_cosine_decay_schedule\"\n",
    "    init_value: float = 0.0\n",
    "    peak_value: float = 1e0\n",
    "    warmup_steps: int = 500\n",
    "    end_value: float = 1e-5\n",
    "    \n",
    "scheduler_config = OmegaConf.structured(Scheduler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a8676fe-0cac-465f-a1bc-f1951b1b6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4_000\n",
    "num_steps_per_epoch = len(dm.ds_train)\n",
    "\n",
    "scheduler = hydra.utils.instantiate(\n",
    "    scheduler_config, decay_steps=int(num_epochs * num_steps_per_epoch)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "461daefc-c58b-48e1-8ba3-9322095a21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.chain(optim, optax.scale_by_schedule(scheduler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327bdf1-7e7d-458c-99f7-2d85ba48d185",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Trainer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a54b919-1dd4-4bad-bd4d-1c9d4dc92a0f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from jejeqx._src.trainers.base import TrainerModule\n",
    "from jejeqx._src.trainers.callbacks import wandb_model_artifact\n",
    "from jejeqx._src.losses import psnr\n",
    "\n",
    "\n",
    "class RegressorTrainer(TrainerModule):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 optimizer,\n",
    "                 **kwargs):\n",
    "        super().__init__(\n",
    "            model=model, \n",
    "            optimizer=optimizer, \n",
    "            pl_logger=None,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "    @property\n",
    "    def model(self):\n",
    "        return self.state.params\n",
    "\n",
    "    @property\n",
    "    def model_batch(self):\n",
    "        return jax.vmap(self.state.params, in_axes=(0,0))\n",
    "\n",
    "    def create_functions(self):\n",
    "\n",
    "        @eqx.filter_value_and_grad\n",
    "        def mse_loss(model, batch):\n",
    "            x, t, y = batch[\"spatial\"], batch[\"temporal\"], batch[\"data\"]\n",
    "            # pred = jax.vmap(model, in_axes=(0,0))(x, t)\n",
    "            pred = jax.vmap(model)(jnp.hstack([x, t]))\n",
    "            loss = jnp.mean((y - pred)**2)\n",
    "            return loss\n",
    "        \n",
    "        def train_step(state, batch):\n",
    "            \n",
    "            loss, grads = mse_loss(state.params, batch)\n",
    "            state = state.update_state(state, grads)\n",
    "            psnr_loss = psnr(loss) \n",
    "            metrics = {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "            return state, loss, metrics\n",
    "\n",
    "        def eval_step(model, batch):\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss) \n",
    "            return {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "        \n",
    "        def predict_step(model, batch):\n",
    "            x, t, y = batch[\"spatial\"], batch[\"temporal\"], batch[\"data\"]\n",
    "            pred = jax.vmap(model)(jnp.hstack([x, t]))\n",
    "            loss, _ = mse_loss(model, batch)\n",
    "            psnr_loss = psnr(loss)\n",
    "            return pred, {\"loss\": loss, \"psnr\": psnr_loss}\n",
    "\n",
    "        return train_step, eval_step, predict_step\n",
    "    \n",
    "    \n",
    "    def on_training_end(self,):\n",
    "        \n",
    "        if self.pl_logger:\n",
    "            save_dir = Path(self.log_dir).joinpath(self.save_name)\n",
    "            self.save_model(save_dir)\n",
    "            wandb_model_artifact(self)\n",
    "            self.pl_logger.finalize(\"success\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1df158c-9126-4e8e-b5ab-ae01c0a34c06",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "debug = False\n",
    "enable_progress_bar = False\n",
    "log_dir = \"./\"\n",
    "\n",
    "trainer = RegressorTrainer(\n",
    "    model, \n",
    "    optimizer, \n",
    "    seed=seed, \n",
    "    debug=debug, \n",
    "    enable_progress_bar=enable_progress_bar,\n",
    "    log_dir=log_dir\n",
    ")\n",
    "\n",
    "train_more = True\n",
    "save_more = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54591d79-21a2-4787-8bb8-7f25c595f2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.17 s, sys: 143 ms, total: 5.31 s\n",
      "Wall time: 4.79 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.3045758605003357, 'psnr': 7.7384138107299805}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.predict_model(dm.predict_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6dff88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if model_name == \"rff\":\n",
    "    # trainer.load_model(\"./checkpoints/checkpoint_model_rff_ssh_swot.ckpt\")\n",
    "    trainer.load_model(\"./checkpoints/checkpoint_natl60_model_rff.ckpt\")\n",
    "elif model_name == \"siren\":\n",
    "    trainer.load_model(\"./checkpoints/checkpoint_model_siren_ssh_swot.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8616b022-0b0b-42bd-ad8a-eb8683311ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.88 s, sys: 58.9 ms, total: 4.94 s\n",
      "Wall time: 3.96 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.26487576961517334, 'psnr': 8.66219425201416}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.predict_model(dm.predict_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b5d0fd-628d-45f4-8eff-21be28d1c977",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs: 2215 | Loss: 1.744e-04:  55%|█████▌    | 2215/4000 [44:52<37:21,  1.26s/it]  "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "metrics = trainer.train_model(dm, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad3663-3e31-4504-a584-fadb4a5b0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.predict_model(dm.predict_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c874f6c-49ba-431a-8bea-75ae0ccfa045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20449b9d-6229-400b-8502-ac280a2faf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_more:\n",
    "    if model_name == \"rff\":\n",
    "        trainer.save_model(\"./checkpoints/checkpoint_model_rff_ssh_swot.ckpt\")\n",
    "    elif model_name == \"siren\":\n",
    "        trainer.save_model(\"./checkpoints/checkpoint_model_siren_ssh_swot.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d51ff8-ad49-4d64-bafe-b54a044adcd3",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We will predict the whole dataset at the full resolution available for the same time period.\n",
    "\n",
    "`01-June-2013 :--> 15-June-2013`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894b25c-5ade-4270-9294-4927cf90b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict\n",
    "\n",
    "@dataclass\n",
    "class Subset:\n",
    "    _target_: str = \"builtins.slice\"\n",
    "    _args_: List = field(default_factory=lambda :[\"2013-01-01\", \"2013-01-10\"])\n",
    "\n",
    "    files = [\n",
    "    \"/gpfswork/rech/yrf/commun/data_challenges/dc20a_osse/work_eman/ml_ready/nadir1.nc\",\n",
    "    \"/gpfswork/rech/yrf/commun/data_challenges/dc20a_osse/work_eman/ml_ready/swot1nadir1.nc\",\n",
    "]\n",
    "\n",
    "@dataclass\n",
    "class SSHDMEVAL:\n",
    "    _target_: str = \"jejeqx._src.datamodules.coords.EvalCoordDM\"\n",
    "    paths: str = \"/gpfswork/rech/yrf/commun/data_challenges/dc20a_osse/test/dc_ref/NATL60-CJM165_GULFSTREAM*\"\n",
    "    batch_size: int = 10_000\n",
    "    shuffle: bool = False\n",
    "    train_size: float = 0.80\n",
    "    spatial_coords: List = field(default_factory=lambda : [\"lat\", \"lon\"])\n",
    "    temporal_coords: List = field(default_factory=lambda: [\"time\"])\n",
    "    variables: List = field(default_factory=lambda : [\"sossheig\"])\n",
    "    coarsen: Dict = field(default_factory=lambda : {\"lon\": 2, \"lat\": 2})\n",
    "    resample: str = \"1D\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c2fae-0d76-455c-abb5-2374f26325d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial transform\n",
    "spatial_transforms = Pipeline([\n",
    "    (\"cartesian3d\", Spherical2Cartesian(radius=1.0, units=\"degrees\")),\n",
    "    (\"spatialminmax\", MinMaxDF([\"x\", \"y\", \"z\"], -1, 1)),\n",
    "])\n",
    "\n",
    "temporal_transforms = Pipeline([\n",
    "    (\"timedelta\", TimeDelta(\"2012-10-01\", 1, \"s\")),\n",
    "    (\"timeminmax\", MinMaxDF([\"time\"], -1, 1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9f1ee9-07d7-4d76-82b8-69453a87e036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "select = {\"time\": slice(\"2012-10-22\", \"2012-11-22\")}\n",
    "\n",
    "config_dm = OmegaConf.structured(SSHDMEVAL())\n",
    "\n",
    "dm_eval = hydra.utils.instantiate(\n",
    "    config_dm,\n",
    "    select=select,\n",
    "    spatial_transform=spatial_transforms,\n",
    "    temporal_transform=temporal_transforms\n",
    ")\n",
    "\n",
    "dm_eval.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ca3be9-35e9-40e8-beac-736a1cf4fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dm_eval.ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2d527f-181e-4ca1-8da1-a586246dd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda = dm_eval.load_xrds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54a93cc-dff4-4c91-a121-e17a57ce69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "out, metrics = trainer.predict_model(dm_eval.predict_dataloader())\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1336da9-e5aa-4611-bffe-311e810c4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrda[\"ssh_siren\"] = dm_eval.data_to_df(out).to_xarray().sossheig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b59b43-807f-4e14-8b63-6cf8317925ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "itime = -1\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(8,3))\n",
    "\n",
    "vmin = np.min([xrda.sossheig.min(), xrda.ssh_siren.min()])\n",
    "vmax = np.min([xrda.sossheig.max(), xrda.ssh_siren.max()])\n",
    "\n",
    "xrda.sossheig.isel(time=itime).plot.pcolormesh(\n",
    "    ax=ax[0], cmap=\"viridis\", vmin=vmin, vmax=vmax, robust=True\n",
    ")\n",
    "ax[0].set(title=\"Original\")\n",
    "\n",
    "xrda.ssh_siren.isel(time=itime).plot.pcolormesh(\n",
    "    ax=ax[1], cmap=\"viridis\", vmin=vmin, vmax=vmax, robust=True\n",
    ")\n",
    "ax[1].set(title=\"Latent Mod Siren\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40dcdb6-4f29-4ff2-b7a1-75e033289329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pint import UnitRegistry\n",
    "from metpy.constants import earth_gravity as GRAVITY\n",
    "\n",
    "def get_analysis_xr(da, g: float=GRAVITY):\n",
    "    \n",
    "    da.name = \"ssh\"\n",
    "    da.attrs[\"units\"] = \"m\"\n",
    "    da.attrs[\"long_name\"] = \"Sea Surface Height\"\n",
    "    da.attrs[\"standard_name\"] = \"sea_surface_height\"\n",
    "    \n",
    "    da.time.attrs[\"long_name\"] = \"Time\"\n",
    "    da.time.attrs[\"standard_name\"] = \"time\"\n",
    "    \n",
    "    da.lon.attrs[\"units\"] = \"degrees_east\"\n",
    "    da.lon.attrs[\"long_name\"] = \"Longitude\"\n",
    "    da.lon.attrs[\"standard_name\"] = \"longitude\"\n",
    "    \n",
    "    da.lat.attrs[\"units\"] = \"degrees_north\"\n",
    "    da.lat.attrs[\"long_name\"] = \"Latitude\"\n",
    "    da.lat.attrs[\"standard_name\"] = \"latitude\"\n",
    "    \n",
    "    ds = da.to_dataset()\n",
    "    \n",
    "    dx, dy = metpy.calc.lat_lon_grid_deltas(longitude=ds.lon, latitude=ds.lat)\n",
    "    \n",
    "    f = metpy.calc.coriolis_parameter(latitude=np.deg2rad(ds.lat.values))\n",
    "    \n",
    "    f0 = f.mean()\n",
    "        \n",
    "    psi = (g/f0) * da \n",
    "    ds[\"psi\"] = ((\"time\", \"lat\", \"lon\"), psi.data)\n",
    "    \n",
    "    dpsi_dx, dpsi_dy = metpy.calc.geospatial_gradient(\n",
    "        f=psi, latitude=ds.lat, longitude=ds.lon\n",
    "    )\n",
    "    \n",
    "    ds[\"u\"] = ((\"time\", \"lat\", \"lon\"), - dpsi_dy.magnitude)\n",
    "    ds[\"u\"].attrs[\"units\"] = dpsi_dy.u\n",
    "    ds[\"u\"].attrs[\"long_name\"] = \"Zonal Velocity\"\n",
    "    ds[\"u\"].attrs[\"standard_name\"] = \"zonal_velocity\"\n",
    "    \n",
    "    ds[\"v\"] = ((\"time\", \"lat\", \"lon\"), dpsi_dx.magnitude)\n",
    "    ds[\"v\"].attrs[\"units\"] = dpsi_dx.u\n",
    "    ds[\"v\"].attrs[\"long_name\"] = \"Meridional Velocity\"\n",
    "    ds[\"v\"].attrs[\"standard_name\"] = \"meridional_velocity\"\n",
    "    \n",
    "    \n",
    "    q = metpy.calc.geospatial_laplacian(f=psi, latitude=ds.lat, longitude=ds.lon)\n",
    "    q /= f0\n",
    "    ds[\"q\"] = ((\"time\", \"lat\", \"lon\"), q.values)\n",
    "    ds[\"q\"].attrs[\"units\"] = q.data.u\n",
    "    ds[\"q\"].attrs[\"long_name\"] = \"Relative Vorticity\"\n",
    "    ds[\"q\"].attrs[\"standard_name\"] = \"relative_vorticity\"\n",
    "        \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053cf2b-01a8-472f-a99a-5a8e32b8511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da1b2a-88c7-4601-b9c7-8b98d1a6aea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plot_analysis(ds, time: int=0):\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=4, figsize=(20,4))\n",
    "    \n",
    "    ds.ssh.isel(time=time).plot.pcolormesh(ax=ax[0], cmap=\"viridis\")\n",
    "    ds.u.isel(time=time).plot.pcolormesh(ax=ax[1], cmap=\"gray\")\n",
    "    ds.v.isel(time=time).plot.pcolormesh(ax=ax[2], cmap=\"gray\")\n",
    "    ds.q.isel(time=time).plot.pcolormesh(ax=ax[3], cmap=\"RdBu_r\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5789b665-2a1b-4e7e-8ddd-a9f83e43c886",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### NATL60 Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf1e64-8ed3-4c77-8431-26a0dd96ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ssh_analysis = get_analysis_xr(xrda.sossheig)\n",
    "\n",
    "plot_analysis(ds_ssh_analysis, time=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e0f20-7a64-4e55-a71c-cc43aaee077d",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "#### Latent Modulated SIREN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a6f87-5354-418f-bf9c-4a123a5c482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lmodsiren_analysis = get_analysis_xr(xrda.ssh_siren)\n",
    "\n",
    "plot_analysis(ds_lmodsiren_analysis, time=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60df61c4-c24a-43d9-8277-dc14119d9cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61b7408-5dfd-483f-936a-3714818e9ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-jejeqx]",
   "language": "python",
   "name": "conda-env-miniconda3-jejeqx-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
