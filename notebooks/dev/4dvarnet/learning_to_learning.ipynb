{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning to Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import autoroot\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function as:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{y} = \\boldsymbol{f}(\\mathbf{x})\n",
    "$$\n",
    "\n",
    "We can the function as\n",
    "\n",
    "$$\n",
    "\\boldsymbol{f}(\\mathbf{x};\\boldsymbol{\\theta}) = \\mathbf{wx}\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\theta}=\\{ \\mathbf{w}\\}$ are the parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define a loss function as the MSE:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{L}(\\mathbf{x};\\boldsymbol{\\theta}) = \n",
    "||\\mathbf{wx} \n",
    "- \\mathbf{y} ||_2^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\boldsymbol{R}(\\mathbf{x};\\boldsymbol{\\theta}) = \n",
    "\\alpha||\\mathbf{w}||_2^2\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}^*(\\boldsymbol{\\theta}) = \n",
    "\\underset{\\mathbf{x}}{\\text{argmin}} \\hspace{2mm}\n",
    "\\boldsymbol{J}(\\mathbf{x};\\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter Estimation**\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^{(k+1)} = \n",
    "\\mathbf{x}^{(k)} +\n",
    "\\boldsymbol{g}_k\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimizer function, $\\boldsymbol{g}(\\cdot)$, defined as:\n",
    "\n",
    "$$\n",
    "\\left[ \\boldsymbol{g}_k, \\boldsymbol{h}_{k+1}\\right] =\n",
    "\\boldsymbol{g}\n",
    "\\left( \\boldsymbol{\\nabla}_{\\mathbf{x}}\\boldsymbol{L}(\\mathbf{x};\\boldsymbol{\\theta}), \\boldsymbol{h}_k \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "import equinox as eqx\n",
    "from jaxtyping import Array\n",
    "\n",
    "\n",
    "class LinearModel(eqx.Module):\n",
    "    weight: Array\n",
    "\n",
    "    def __init__(self, dim_in, dim_out, key=jrandom.PRNGKey(123)):\n",
    "\n",
    "        self.weight = jrandom.normal(key=key, shape=(dim_out, dim_in))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return jnp.matmul(self.weight, x)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective Function**\n",
    "\n",
    "$$\n",
    "\\boldsymbol{J}(\\mathbf{x};\\boldsymbol{\\theta}) =\n",
    "\\boldsymbol{L}(\\mathbf{x};\\boldsymbol{\\theta}) +\n",
    "\\lambda\n",
    "\\boldsymbol{R}(\\mathbf{x};\\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Fidelity Term**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{L}(\\mathbf{x};\\boldsymbol{\\theta}) &=\n",
    "||\\mathbf{y} - \\boldsymbol{f}(\\mathbf{x};\\boldsymbol{\\theta})||_2^2 \\\\\n",
    "&= ||\\mathbf{y} - \\mathbf{xw}||_2^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regularization Term**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\boldsymbol{R}(\\boldsymbol{\\theta}) &=\n",
    "||\\boldsymbol{\\theta}||_2^2 \\\\\n",
    "&= ||\\mathbf{w}||_2^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeLoss(eqx.Module):\n",
    "    alpha: Array\n",
    "    model: tp.Callable = LinearModel\n",
    "\n",
    "    def __init__(self, model: tp.Callable, alpha=0.1):\n",
    "        self.model = model\n",
    "        self.alpha = jnp.asarray(alpha)\n",
    "\n",
    "    def data_loss(self, x, y):\n",
    "        y_pred = self.model(x)\n",
    "        return jnp.mean(y_pred - y)\n",
    "    \n",
    "    def reg_loss(self):\n",
    "        return jnp.sum(self.model.weight ** 2)\n",
    "\n",
    "    def loss(self, x, y, return_losses: bool=False):\n",
    "        \n",
    "        # data loss\n",
    "        data_loss = 0.5 * self.data_loss(x, y)\n",
    "\n",
    "        # reg loss\n",
    "        reg_loss = 0.5 * self.alpha * self.reg_loss()\n",
    "\n",
    "        # total loss\n",
    "        loss = data_loss + reg_loss\n",
    "\n",
    "        if return_losses:\n",
    "            losses = dict(loss=loss, data=data_loss, reg=reg_loss)\n",
    "            return loss, losses\n",
    "        else:\n",
    "            return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1,), (1,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = jnp.ones((10,))\n",
    "y = jnp.ones((1,))\n",
    "\n",
    "lr_model = LinearModel(10, 1)\n",
    "y_pred = lr_model(x)\n",
    "y_pred.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-2.0766206, dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_loss = RidgeLoss(lr_model, alpha=0.01)\n",
    "\n",
    "ridge_loss.loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaxopt_loss(model, x, y):\n",
    "    return model.loss(x, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x}^*(\\boldsymbol{\\theta}) =\n",
    "\\underset{\\mathbf{x}}{\\text{argmin}} \\hspace{2mm}\n",
    "\\boldsymbol{J}(\\mathbf{x};\\boldsymbol{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxopt import OptaxSolver\n",
    "import jaxopt\n",
    "import optax\n",
    "\n",
    "learning_rate = 1e-3\n",
    "maxiter = 100\n",
    "\n",
    "opt = optax.adam(learning_rate)\n",
    "# solver = OptaxSolver(opt=opt, fun=jaxopt_loss, maxiter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = jaxopt.LBFGS(fun=jaxopt_loss, maxiter=maxiter)\n",
    "res = solver.run(ridge_loss, x=x, y=y)\n",
    "\n",
    "# Alternatively, we could have used one of these solvers as well:\n",
    "# solver = jaxopt.GradientDescent(fun=ridge_reg_objective, maxiter=500)\n",
    "# solver = jaxopt.ScipyMinimize(fun=ridge_reg_objective, method=\"L-BFGS-B\", maxiter=500)\n",
    "# solver = jaxopt.NonlinearCG(fun=ridge_reg_objective, method=\"polak-ribiere\", maxiter=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = optax.adam(learning_rate)\n",
    "\n",
    "def jaxopt_soln(x, y):\n",
    "  gd = OptaxSolver(opt=opt, fun=jaxopt_loss, maxiter=1000, implicit_diff=True)\n",
    "  # gd = jaxopt.LBFGS(fun=jaxopt_loss, maxiter=500, implicit_diff=True, )\n",
    "  # gd = jaxopt.GradientDescent(fun=jaxopt_loss, maxiter=500, implicit_diff=True, )\n",
    "  return gd.run(ridge_loss, x=x, y=y).params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(-1.2881405, dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soln  = jaxopt_soln(x, y)\n",
    "soln.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.01, dtype=float32),\n",
       " Array([[-0.10502207, -0.56205004, -0.56485987, -1.7063935 ,  0.56626016,\n",
       "         -0.42215332,  1.0077653 ,  0.9922631 , -0.61236995, -1.8450408 ]],      dtype=float32))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.params.alpha, res.params.model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LbfgsState(iter_num=Array(100, dtype=int32, weak_type=True), value=Array(-2.0766206, dtype=float32), grad=RidgeLoss(alpha=f32[], model=LinearModel(weight=f32[1,10])), stepsize=Array(0., dtype=float32), error=Array(5.1628613, dtype=float32), s_history=RidgeLoss(alpha=f32[10], model=LinearModel(weight=f32[10,1,10])), y_history=RidgeLoss(alpha=f32[10], model=LinearModel(weight=f32[10,1,10])), rho_history=Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), gamma=Array(1., dtype=float32), aux=None, failed_linesearch=Array(True, dtype=bool))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jejeqx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
