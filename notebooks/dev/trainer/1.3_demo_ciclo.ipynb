{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Regression\n",
    "\n",
    "In this notebook, we will look showcase how to implement a JAX trainer for research purposes. We will use the documentation from the [uvadlc notebooks](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/guide4/Research_Projects_with_JAX.html) and adapt this to the libraries I would like to use:\n",
    "* serket\n",
    "* optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pyprojroot import here\n",
    "\n",
    "# spyder up to find the root\n",
    "root = here(project_files=[\".home\"])\n",
    "\n",
    "# append to path\n",
    "sys.path.append(str(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cifar = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 3),\n",
    "    classes=100,\n",
    ")\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import sys\n",
    "from typing import Any, Sequence, Optional, Tuple, Iterator, Dict, Callable, Union\n",
    "import json\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "# JAX/Flax\n",
    "# If you run this code on Colab, remember to install flax and optax\n",
    "# !pip install --quiet --upgrade flax optax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from flax import linen as nn\n",
    "\n",
    "# from flax.training import train_state, checkpoints\n",
    "import optax\n",
    "\n",
    "# PyTorch for data loading\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Logging with Tensorboard or Weights and Biases\n",
    "# If you run this code on Colab, remember to install pytorch_lightning\n",
    "# !pip install --quiet --upgrade pytorch_lightning\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats(\"svg\", \"pdf\")  # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams[\"lines.linewidth\"] = 2.0\n",
    "sns.reset_defaults()\n",
    "sns.set_context(context=\"talk\", font_scale=0.7)\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_function(x):\n",
    "    return np.sin(x * 3.0)\n",
    "\n",
    "\n",
    "class RegressionDataset(data.Dataset):\n",
    "    def __init__(self, num_points, seed):\n",
    "        super().__init__()\n",
    "        rng = np.random.default_rng(seed)\n",
    "        self.x = rng.uniform(low=-2.0, high=2.0, size=num_points)\n",
    "        self.y = target_function(self.x)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx : idx + 1], self.y[idx : idx + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = RegressionDataset(num_points=1000, seed=42)\n",
    "val_set = RegressionDataset(num_points=200, seed=43)\n",
    "test_set = RegressionDataset(num_points=500, seed=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2, 1000)\n",
    "plt.scatter(\n",
    "    train_set.x, train_set.y, color=\"C1\", marker=\"x\", alpha=0.5, label=\"Training set\"\n",
    ")\n",
    "plt.plot(x, target_function(x), linewidth=3.0, label=\"Ground Truth Function\")\n",
    "plt.legend()\n",
    "plt.title(\"Regression function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib._src.datamodules.base import NumpyLoader, numpy_collate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loaders(\n",
    "    *datasets: Sequence[data.Dataset],\n",
    "    train: Union[bool, Sequence[bool]] = True,\n",
    "    batch_size: int = 128,\n",
    "    num_workers: int = 4,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    loaders = []\n",
    "    if not isinstance(train, (list, tuple)):\n",
    "        train = [train for _ in datasets]\n",
    "    for dataset, is_train in zip(datasets, train):\n",
    "        loader = data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=is_train,\n",
    "            collate_fn=numpy_collate,\n",
    "            num_workers=num_workers,\n",
    "            persistent_workers=is_train if num_workers > 0 else False,\n",
    "            generator=torch.Generator().manual_seed(seed),\n",
    "        )\n",
    "        loaders.append(loader)\n",
    "\n",
    "    return loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 0\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    train_set,\n",
    "    val_set,\n",
    "    test_set,\n",
    "    train=[True, False, False],\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ibatch in tqdm(train_loader):\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibatch[0].shape, ibatch[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import serket as sk\n",
    "\n",
    "hidden_dims = [128, 128]\n",
    "output_dim = 1\n",
    "\n",
    "model = sk.nn.Sequential([sk.nn.Linear(None, 128), sk.nn.SILU(), sk.nn.Linear(128, 1)])\n",
    "\n",
    "model(jnp.empty_like(ibatch[0]))\n",
    "\n",
    "print(model.summary(show_config=False, array=jnp.empty_like(ibatch[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytreeclass as pytc\n",
    "import optax\n",
    "\n",
    "\n",
    "@pytc.treeclass\n",
    "class TrainState:\n",
    "    step: int = pytc.field(nondiff=True)\n",
    "    model: pytc.treeclass\n",
    "    tx: optax.GradientTransformation = pytc.field(nondiff=True)\n",
    "    opt_state: optax.OptState\n",
    "\n",
    "    def apply_gradients(self, *, grads, **kwargs):\n",
    "        updates, new_opt_state = self.tx.update(grads, self.opt_state, self.model)\n",
    "\n",
    "        new_params = optax.apply_updates(self.model, updates)\n",
    "        return self.replace(\n",
    "            step=self.step + 1, params=new_params, opt_state=new_opt_state, **kwargs\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, *, model, tx, **kwargs):\n",
    "        opt_state = tx.init(model)\n",
    "        return cls(step=0, model=model, tx=tx, opt_state=opt_state, **kwargs)\n",
    "\n",
    "\n",
    "# from typing import Any\n",
    "# from flax.training import train_state\n",
    "#\n",
    "#\n",
    "# class TrainState(train_state.TrainState):\n",
    "#     batch_stats: Any = None\n",
    "#     rng: Any = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize state\n",
    "state = TrainState.create(model=model, tx=optax.adamw(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state: TrainState, batch):\n",
    "    inputs, labels = batch\n",
    "\n",
    "    def loss_fn(model):\n",
    "        output = state.model(inputs)\n",
    "        loss = optax.l2_loss(output, labels).mean()\n",
    "        return loss, output\n",
    "\n",
    "    (loss, output), grads = jax.value_and_grad(loss_fn, has_aux=True)(state.model)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    logs = {\"loss\": loss, \"accuracy\": jnp.mean(jnp.square(output, labels))}\n",
    "    return {\"metrics\": logs}, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ciclo\n",
    "\n",
    "# training loop\n",
    "total_samples = len(train_set)\n",
    "total_steps = total_samples // batch_size\n",
    "\n",
    "\n",
    "state, history, _ = ciclo.loop(\n",
    "    state,\n",
    "    train_loader,\n",
    "    {\n",
    "        ciclo.every(1): train_step,\n",
    "        **ciclo.keras_bar(total=total_steps),\n",
    "    },\n",
    "    stop=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerModule:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: pytc.treeclass,\n",
    "        optimizer: Dict[str, Any],\n",
    "        lr_scheduler,\n",
    "        exmp_input: Any,\n",
    "        seed: int = 42,\n",
    "        logger_params: Dict[str, Any] = None,\n",
    "        enable_progress_bar: bool = True,\n",
    "        debug: bool = False,\n",
    "        check_val_every_n_epoch: int = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A basic Trainer module summarizing most common training functionalities\n",
    "        like logging, model initialization, training loop, etc.\n",
    "\n",
    "        Atributes:\n",
    "          model_class: The class of the model that should be trained.\n",
    "          model_hparams: A dictionary of all hyperparameters of the model. Is\n",
    "            used as input to the model when created.\n",
    "          optimizer_hparams: A dictionary of all hyperparameters of the optimizer.\n",
    "            Used during initialization of the optimizer.\n",
    "          exmp_input: Input to the model for initialization and tabulate.\n",
    "          seed: Seed to initialize PRNG.\n",
    "          logger_params: A dictionary containing the specification of the logger.\n",
    "          enable_progress_bar: If False, no progress bar is shown.\n",
    "          debug: If True, no jitting is applied. Can be helpful for debugging.\n",
    "          check_val_every_n_epoch: The frequency with which the model is evaluated\n",
    "            on the validation set.\n",
    "        \"\"\"\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jit all Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainerModule:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_class: nn.Module,\n",
    "        model_hparams: Dict[str, Any],\n",
    "        optimizer_hparams: Dict[str, Any],\n",
    "        exmp_input: Any,\n",
    "        seed: int = 42,\n",
    "        logger_params: Dict[str, Any] = None,\n",
    "        enable_progress_bar: bool = True,\n",
    "        debug: bool = False,\n",
    "        check_val_every_n_epoch: int = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A basic Trainer module summarizing most common training functionalities\n",
    "        like logging, model initialization, training loop, etc.\n",
    "\n",
    "        Atributes:\n",
    "          model_class: The class of the model that should be trained.\n",
    "          model_hparams: A dictionary of all hyperparameters of the model. Is\n",
    "            used as input to the model when created.\n",
    "          optimizer_hparams: A dictionary of all hyperparameters of the optimizer.\n",
    "            Used during initialization of the optimizer.\n",
    "          exmp_input: Input to the model for initialization and tabulate.\n",
    "          seed: Seed to initialize PRNG.\n",
    "          logger_params: A dictionary containing the specification of the logger.\n",
    "          enable_progress_bar: If False, no progress bar is shown.\n",
    "          debug: If True, no jitting is applied. Can be helpful for debugging.\n",
    "          check_val_every_n_epoch: The frequency with which the model is evaluated\n",
    "            on the validation set.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model_class = model_class\n",
    "        self.model_hparams = model_hparams\n",
    "        self.optimizer_hparams = optimizer_hparams\n",
    "        self.enable_progress_bar = enable_progress_bar\n",
    "        self.debug = debug\n",
    "        self.seed = seed\n",
    "        self.check_val_every_n_epoch = check_val_every_n_epoch\n",
    "        self.exmp_input = exmp_input\n",
    "        # Set of hyperparameters to save\n",
    "        self.config = {\n",
    "            \"model_class\": model_class.__name__,\n",
    "            \"model_hparams\": model_hparams,\n",
    "            \"optimizer_hparams\": optimizer_hparams,\n",
    "            \"logger_params\": logger_params,\n",
    "            \"enable_progress_bar\": self.enable_progress_bar,\n",
    "            \"debug\": self.debug,\n",
    "            \"check_val_every_n_epoch\": check_val_every_n_epoch,\n",
    "            \"seed\": self.seed,\n",
    "        }\n",
    "        self.config.update(kwargs)\n",
    "        # Create empty model. Note: no parameters yet\n",
    "        self.model = self.model_class(**self.model_hparams)\n",
    "        self.print_tabulate(exmp_input)\n",
    "        # Init trainer parts\n",
    "        self.init_logger(logger_params)\n",
    "        self.create_jitted_functions()\n",
    "        self.init_model(exmp_input)\n",
    "\n",
    "    def init_logger(self, logger_params: Optional[Dict] = None):\n",
    "        \"\"\"\n",
    "        Initializes a logger and creates a logging directory.\n",
    "\n",
    "        Args:\n",
    "          logger_params: A dictionary containing the specification of the logger.\n",
    "        \"\"\"\n",
    "        if logger_params is None:\n",
    "            logger_params = dict()\n",
    "        # Determine logging directory\n",
    "        log_dir = logger_params.get(\"log_dir\", None)\n",
    "        if not log_dir:\n",
    "            base_log_dir = logger_params.get(\"base_log_dir\", \"checkpoints/\")\n",
    "            # Prepare logging\n",
    "            log_dir = os.path.join(base_log_dir, self.config[\"model_class\"])\n",
    "            if \"logger_name\" in logger_params:\n",
    "                log_dir = os.path.join(log_dir, logger_params[\"logger_name\"])\n",
    "            version = None\n",
    "        else:\n",
    "            version = \"\"\n",
    "        # Create logger object\n",
    "        logger_type = logger_params.get(\"logger_type\", \"TensorBoard\").lower()\n",
    "        if logger_type == \"tensorboard\":\n",
    "            self.logger = TensorBoardLogger(save_dir=log_dir, version=version, name=\"\")\n",
    "        elif logger_type == \"wandb\":\n",
    "            self.logger = WandbLogger(\n",
    "                name=logger_params.get(\"project_name\", None),\n",
    "                save_dir=log_dir,\n",
    "                version=version,\n",
    "                config=self.config,\n",
    "            )\n",
    "        else:\n",
    "            assert False, f'Unknown logger type \"{logger_type}\"'\n",
    "        # Save hyperparameters\n",
    "        log_dir = self.logger.log_dir\n",
    "        if not os.path.isfile(os.path.join(log_dir, \"hparams.json\")):\n",
    "            os.makedirs(os.path.join(log_dir, \"metrics/\"), exist_ok=True)\n",
    "            with open(os.path.join(log_dir, \"hparams.json\"), \"w\") as f:\n",
    "                json.dump(self.config, f, indent=4)\n",
    "        self.log_dir = log_dir\n",
    "\n",
    "    def init_model(self, exmp_input: Any):\n",
    "        \"\"\"\n",
    "        Creates an initial training state with newly generated network parameters.\n",
    "\n",
    "        Args:\n",
    "          exmp_input: An input to the model with which the shapes are inferred.\n",
    "        \"\"\"\n",
    "        # Prepare PRNG and input\n",
    "        model_rng = random.PRNGKey(self.seed)\n",
    "        model_rng, init_rng = random.split(model_rng)\n",
    "        exmp_input = (\n",
    "            [exmp_input] if not isinstance(exmp_input, (list, tuple)) else exmp_input\n",
    "        )\n",
    "        # Run model initialization\n",
    "        variables = self.run_model_init(exmp_input, init_rng)\n",
    "        # Create default state. Optimizer is initialized later\n",
    "        self.state = TrainState(\n",
    "            step=0,\n",
    "            apply_fn=self.model.apply,\n",
    "            params=variables[\"params\"],\n",
    "            batch_stats=variables.get(\"batch_stats\"),\n",
    "            rng=model_rng,\n",
    "            tx=None,\n",
    "            opt_state=None,\n",
    "        )\n",
    "\n",
    "    def run_model_init(self, exmp_input: Any, init_rng: Any) -> Dict:\n",
    "        \"\"\"\n",
    "        The model initialization call\n",
    "\n",
    "        Args:\n",
    "          exmp_input: An input to the model with which the shapes are inferred.\n",
    "          init_rng: A jax.random.PRNGKey.\n",
    "\n",
    "        Returns:\n",
    "          The initialized variable dictionary.\n",
    "        \"\"\"\n",
    "        return self.model.init(init_rng, *exmp_input, train=True)\n",
    "\n",
    "    def print_tabulate(self, exmp_input: Any):\n",
    "        \"\"\"\n",
    "        Prints a summary of the Module represented as table.\n",
    "\n",
    "        Args:\n",
    "          exmp_input: An input to the model with which the shapes are inferred.\n",
    "        \"\"\"\n",
    "        print(self.model.tabulate(random.PRNGKey(0), *exmp_input, train=True))\n",
    "\n",
    "    def init_optimizer(self, num_epochs: int, num_steps_per_epoch: int):\n",
    "        \"\"\"\n",
    "        Initializes the optimizer and learning rate scheduler.\n",
    "\n",
    "        Args:\n",
    "          num_epochs: Number of epochs the model will be trained for.\n",
    "          num_steps_per_epoch: Number of training steps per epoch.\n",
    "        \"\"\"\n",
    "        hparams = copy(self.optimizer_hparams)\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer_name = hparams.pop(\"optimizer\", \"adamw\")\n",
    "        if optimizer_name.lower() == \"adam\":\n",
    "            opt_class = optax.adam\n",
    "        elif optimizer_name.lower() == \"adamw\":\n",
    "            opt_class = optax.adamw\n",
    "        elif optimizer_name.lower() == \"sgd\":\n",
    "            opt_class = optax.sgd\n",
    "        else:\n",
    "            assert False, f'Unknown optimizer \"{opt_class}\"'\n",
    "        # Initialize learning rate scheduler\n",
    "        # A cosine decay scheduler is used, but others are also possible\n",
    "        lr = hparams.pop(\"lr\", 1e-3)\n",
    "        warmup = hparams.pop(\"warmup\", 0)\n",
    "        lr_schedule = optax.warmup_cosine_decay_schedule(\n",
    "            init_value=0.0,\n",
    "            peak_value=lr,\n",
    "            warmup_steps=warmup,\n",
    "            decay_steps=int(num_epochs * num_steps_per_epoch),\n",
    "            end_value=0.01 * lr,\n",
    "        )\n",
    "        # Clip gradients at max value, and evt. apply weight decay\n",
    "        transf = [optax.clip_by_global_norm(hparams.pop(\"gradient_clip\", 1.0))]\n",
    "        if (\n",
    "            opt_class == optax.sgd and \"weight_decay\" in hparams\n",
    "        ):  # wd is integrated in adamw\n",
    "            transf.append(optax.add_decayed_weights(hparams.pop(\"weight_decay\", 0.0)))\n",
    "        optimizer = optax.chain(*transf, opt_class(lr_schedule, **hparams))\n",
    "        # Initialize training state\n",
    "        self.state = TrainState.create(\n",
    "            apply_fn=self.state.apply_fn,\n",
    "            params=self.state.params,\n",
    "            batch_stats=self.state.batch_stats,\n",
    "            tx=optimizer,\n",
    "            rng=self.state.rng,\n",
    "        )\n",
    "\n",
    "    def create_jitted_functions(self):\n",
    "        \"\"\"\n",
    "        Creates jitted versions of the training and evaluation functions.\n",
    "        If self.debug is True, not jitting is applied.\n",
    "        \"\"\"\n",
    "        train_step, eval_step = self.create_functions()\n",
    "        if self.debug:  # Skip jitting\n",
    "            print(\"Skipping jitting due to debug=True\")\n",
    "            self.train_step = train_step\n",
    "            self.eval_step = eval_step\n",
    "        else:\n",
    "            self.train_step = jax.jit(train_step)\n",
    "            self.eval_step = jax.jit(eval_step)\n",
    "\n",
    "    def create_functions(\n",
    "        self,\n",
    "    ) -> Tuple[\n",
    "        Callable[[TrainState, Any], Tuple[TrainState, Dict]],\n",
    "        Callable[[TrainState, Any], Tuple[TrainState, Dict]],\n",
    "    ]:\n",
    "        \"\"\"\n",
    "        Creates and returns functions for the training and evaluation step. The\n",
    "        functions take as input the training state and a batch from the train/\n",
    "        val/test loader. Both functions are expected to return a dictionary of\n",
    "        logging metrics, and the training function a new train state. This\n",
    "        function needs to be overwritten by a subclass. The train_step and\n",
    "        eval_step functions here are examples for the signature of the functions.\n",
    "        \"\"\"\n",
    "\n",
    "        def train_step(state: TrainState, batch: Any):\n",
    "            metrics = {}\n",
    "            return state, metrics\n",
    "\n",
    "        def eval_step(state: TrainState, batch: Any):\n",
    "            metrics = {}\n",
    "            return metrics\n",
    "\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_model(\n",
    "        self,\n",
    "        train_loader: Iterator,\n",
    "        val_loader: Iterator,\n",
    "        test_loader: Optional[Iterator] = None,\n",
    "        num_epochs: int = 500,\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Starts a training loop for the given number of epochs.\n",
    "\n",
    "        Args:\n",
    "          train_loader: Data loader of the training set.\n",
    "          val_loader: Data loader of the validation set.\n",
    "          test_loader: If given, best model will be evaluated on the test set.\n",
    "          num_epochs: Number of epochs for which to train the model.\n",
    "\n",
    "        Returns:\n",
    "          A dictionary of the train, validation and evt. test metrics for the\n",
    "          best model on the validation set.\n",
    "        \"\"\"\n",
    "        # Create optimizer and the scheduler for the given number of epochs\n",
    "        self.init_optimizer(num_epochs, len(train_loader))\n",
    "        # Prepare training loop\n",
    "        self.on_training_start()\n",
    "        best_eval_metrics = None\n",
    "        for epoch_idx in self.tracker(range(1, num_epochs + 1), desc=\"Epochs\"):\n",
    "            train_metrics = self.train_epoch(train_loader)\n",
    "            self.logger.log_metrics(train_metrics, step=epoch_idx)\n",
    "            self.on_training_epoch_end(epoch_idx)\n",
    "            # Validation every N epochs\n",
    "            if epoch_idx % self.check_val_every_n_epoch == 0:\n",
    "                eval_metrics = self.eval_model(val_loader, log_prefix=\"val/\")\n",
    "                self.on_validation_epoch_end(epoch_idx, eval_metrics, val_loader)\n",
    "                self.logger.log_metrics(eval_metrics, step=epoch_idx)\n",
    "                self.save_metrics(f\"eval_epoch_{str(epoch_idx).zfill(3)}\", eval_metrics)\n",
    "                # Save best model\n",
    "                if self.is_new_model_better(eval_metrics, best_eval_metrics):\n",
    "                    best_eval_metrics = eval_metrics\n",
    "                    best_eval_metrics.update(train_metrics)\n",
    "                    self.save_model(step=epoch_idx)\n",
    "                    self.save_metrics(\"best_eval\", eval_metrics)\n",
    "        # Test best model if possible\n",
    "        if test_loader is not None:\n",
    "            self.load_model()\n",
    "            test_metrics = self.eval_model(test_loader, log_prefix=\"test/\")\n",
    "            self.logger.log_metrics(test_metrics, step=epoch_idx)\n",
    "            self.save_metrics(\"test\", test_metrics)\n",
    "            best_eval_metrics.update(test_metrics)\n",
    "        # Close logger\n",
    "        self.logger.finalize(\"success\")\n",
    "        return best_eval_metrics\n",
    "\n",
    "    def train_epoch(self, train_loader: Iterator) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Trains a model for one epoch.\n",
    "\n",
    "        Args:\n",
    "          train_loader: Data loader of the training set.\n",
    "\n",
    "        Returns:\n",
    "          A dictionary of the average training metrics over all batches\n",
    "          for logging.\n",
    "        \"\"\"\n",
    "        # Train model for one epoch, and log avg loss and accuracy\n",
    "        metrics = defaultdict(float)\n",
    "        num_train_steps = len(train_loader)\n",
    "        start_time = time.time()\n",
    "        for batch in self.tracker(train_loader, desc=\"Training\", leave=False):\n",
    "            self.state, step_metrics = self.train_step(self.state, batch)\n",
    "            for key in step_metrics:\n",
    "                metrics[\"train/\" + key] += step_metrics[key] / num_train_steps\n",
    "        metrics = {key: metrics[key].item() for key in metrics}\n",
    "        metrics[\"epoch_time\"] = time.time() - start_time\n",
    "        return metrics\n",
    "\n",
    "    def eval_model(\n",
    "        self, data_loader: Iterator, log_prefix: Optional[str] = \"\"\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Evaluates the model on a dataset.\n",
    "\n",
    "        Args:\n",
    "          data_loader: Data loader of the dataset to evaluate on.\n",
    "          log_prefix: Prefix to add to all metrics (e.g. 'val/' or 'test/')\n",
    "\n",
    "        Returns:\n",
    "          A dictionary of the evaluation metrics, averaged over data points\n",
    "          in the dataset.\n",
    "        \"\"\"\n",
    "        # Test model on all images of a data loader and return avg loss\n",
    "        metrics = defaultdict(float)\n",
    "        num_elements = 0\n",
    "        for batch in data_loader:\n",
    "            step_metrics = self.eval_step(self.state, batch)\n",
    "            batch_size = (\n",
    "                batch[0].shape[0]\n",
    "                if isinstance(batch, (list, tuple))\n",
    "                else batch.shape[0]\n",
    "            )\n",
    "            for key in step_metrics:\n",
    "                metrics[key] += step_metrics[key] * batch_size\n",
    "            num_elements += batch_size\n",
    "        metrics = {\n",
    "            (log_prefix + key): (metrics[key] / num_elements).item() for key in metrics\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def is_new_model_better(\n",
    "        self, new_metrics: Dict[str, Any], old_metrics: Dict[str, Any]\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Compares two sets of evaluation metrics to decide whether the\n",
    "        new model is better than the previous ones or not.\n",
    "\n",
    "        Args:\n",
    "          new_metrics: A dictionary of the evaluation metrics of the new model.\n",
    "          old_metrics: A dictionary of the evaluation metrics of the previously\n",
    "            best model, i.e. the one to compare to.\n",
    "\n",
    "        Returns:\n",
    "          True if the new model is better than the old one, and False otherwise.\n",
    "        \"\"\"\n",
    "        if old_metrics is None:\n",
    "            return True\n",
    "        for key, is_larger in [\n",
    "            (\"val/val_metric\", False),\n",
    "            (\"val/acc\", True),\n",
    "            (\"val/loss\", False),\n",
    "        ]:\n",
    "            if key in new_metrics:\n",
    "                if is_larger:\n",
    "                    return new_metrics[key] > old_metrics[key]\n",
    "                else:\n",
    "                    return new_metrics[key] < old_metrics[key]\n",
    "        assert False, f\"No known metrics to log on: {new_metrics}\"\n",
    "\n",
    "    def tracker(self, iterator: Iterator, **kwargs) -> Iterator:\n",
    "        \"\"\"\n",
    "        Wraps an iterator in a progress bar tracker (tqdm) if the progress bar\n",
    "        is enabled.\n",
    "\n",
    "        Args:\n",
    "          iterator: Iterator to wrap in tqdm.\n",
    "          kwargs: Additional arguments to tqdm.\n",
    "\n",
    "        Returns:\n",
    "          Wrapped iterator if progress bar is enabled, otherwise same iterator\n",
    "          as input.\n",
    "        \"\"\"\n",
    "        if self.enable_progress_bar:\n",
    "            return tqdm(iterator, **kwargs)\n",
    "        else:\n",
    "            return iterator\n",
    "\n",
    "    def save_metrics(self, filename: str, metrics: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Saves a dictionary of metrics to file. Can be used as a textual\n",
    "        representation of the validation performance for checking in the terminal.\n",
    "\n",
    "        Args:\n",
    "          filename: Name of the metrics file without folders and postfix.\n",
    "          metrics: A dictionary of metrics to save in the file.\n",
    "        \"\"\"\n",
    "        with open(os.path.join(self.log_dir, f\"metrics/{filename}.json\"), \"w\") as f:\n",
    "            json.dump(metrics, f, indent=4)\n",
    "\n",
    "    def on_training_start(self):\n",
    "        \"\"\"\n",
    "        Method called before training is started. Can be used for additional\n",
    "        initialization operations etc.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def on_training_epoch_end(self, epoch_idx: int):\n",
    "        \"\"\"\n",
    "        Method called at the end of each training epoch. Can be used for additional\n",
    "        logging or similar.\n",
    "\n",
    "        Args:\n",
    "          epoch_idx: Index of the training epoch that has finished.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def on_validation_epoch_end(\n",
    "        self, epoch_idx: int, eval_metrics: Dict[str, Any], val_loader: Iterator\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Method called at the end of each validation epoch. Can be used for additional\n",
    "        logging and evaluation.\n",
    "\n",
    "        Args:\n",
    "          epoch_idx: Index of the training epoch at which validation was performed.\n",
    "          eval_metrics: A dictionary of the validation metrics. New metrics added to\n",
    "            this dictionary will be logged as well.\n",
    "          val_loader: Data loader of the validation set, to support additional\n",
    "            evaluation.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save_model(self, step: int = 0):\n",
    "        \"\"\"\n",
    "        Saves current training state at certain training iteration. Only the model\n",
    "        parameters and batch statistics are saved to reduce memory footprint. To\n",
    "        support the training to be continued from a checkpoint, this method can be\n",
    "        extended to include the optimizer state as well.\n",
    "\n",
    "        Args:\n",
    "          step: Index of the step to save the model at, e.g. epoch.\n",
    "        \"\"\"\n",
    "        checkpoints.save_checkpoint(\n",
    "            ckpt_dir=self.log_dir,\n",
    "            target={\"params\": self.state.params, \"batch_stats\": self.state.batch_stats},\n",
    "            step=step,\n",
    "            overwrite=True,\n",
    "        )\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads model parameters and batch statistics from the logging directory.\n",
    "        \"\"\"\n",
    "        state_dict = checkpoints.restore_checkpoint(ckpt_dir=self.log_dir, target=None)\n",
    "        self.state = TrainState.create(\n",
    "            apply_fn=self.model.apply,\n",
    "            params=state_dict[\"params\"],\n",
    "            batch_stats=state_dict[\"batch_stats\"],\n",
    "            # Optimizer will be overwritten when training starts\n",
    "            tx=self.state.tx if self.state.tx else optax.sgd(0.1),\n",
    "            rng=self.state.rng,\n",
    "        )\n",
    "\n",
    "    def bind_model(self):\n",
    "        \"\"\"\n",
    "        Returns a model with parameters bound to it. Enables an easier inference\n",
    "        access.\n",
    "\n",
    "        Returns:\n",
    "          The model with parameters and evt. batch statistics bound to it.\n",
    "        \"\"\"\n",
    "        params = {\"params\": self.state.params}\n",
    "        if self.state.batch_stats:\n",
    "            params[\"batch_stats\"] = self.state.batch_stats\n",
    "        return self.model.bind(params)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_checkpoint(cls, checkpoint: str, exmp_input: Any) -> Any:\n",
    "        \"\"\"\n",
    "        Creates a Trainer object with same hyperparameters and loaded model from\n",
    "        a checkpoint directory.\n",
    "\n",
    "        Args:\n",
    "          checkpoint: Folder in which the checkpoint and hyperparameter file is stored.\n",
    "          exmp_input: An input to the model for shape inference.\n",
    "\n",
    "        Returns:\n",
    "          A Trainer object with model loaded from the checkpoint folder.\n",
    "        \"\"\"\n",
    "        hparams_file = os.path.join(checkpoint, \"hparams.json\")\n",
    "        assert os.path.isfile(hparams_file), \"Could not find hparams file\"\n",
    "        with open(hparams_file) as f:\n",
    "            hparams = json.load(f)\n",
    "        hparams.pop(\"model_class\")\n",
    "        hparams.update(hparams.pop(\"model_hparams\"))\n",
    "        if not hparams[\"logger_params\"]:\n",
    "            hparams[\"logger_params\"] = dict()\n",
    "        hparams[\"logger_params\"][\"log_dir\"] = checkpoint\n",
    "        trainer = cls(exmp_input=exmp_input, **hparams)\n",
    "        trainer.load_model()\n",
    "        return trainer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jax_eo_py310]",
   "language": "python",
   "name": "conda-env-jax_eo_py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
